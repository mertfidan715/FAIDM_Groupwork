{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIDM Group Project: Complete CRISP-DM Analysis\n",
    "## Student Performance Prediction & Clustering\n",
    "### Open University Learning Analytics Dataset (OULAD)\n",
    "\n",
    "---\n",
    "\n",
    "**Module:** WM9QG-15 Fundamentals of AI and Data Mining\n",
    "\n",
    "**Dataset:** OULAD Mega Table  \n",
    "- **Each row = one student enrolled in one module presentation**\n",
    "- Contains: demographics, VLE engagement, assessment scores, registration info\n",
    "\n",
    "**Tasks:**\n",
    "1. **Classification**: Predict student success (Pass/Distinction) vs failure (Fail/Withdrawn)\n",
    "2. **Clustering**: Segment students by engagement patterns\n",
    "\n",
    "---\n",
    "\n",
    "# 0Ô∏è‚É£ CRISP-DM Overview\n",
    "\n",
    "This notebook follows the **CRISP-DM** (Cross-Industry Standard Process for Data Mining) methodology:\n",
    "\n",
    "| Phase | Description | Sections |\n",
    "|-------|-------------|----------|\n",
    "| 1. Business Understanding | Define objectives and goals | 2Ô∏è‚É£ |\n",
    "| 2. Data Understanding | Explore, visualize, identify quality issues | 3Ô∏è‚É£ |\n",
    "| 3. Data Preparation | Clean, transform, engineer features | 4Ô∏è‚É£ |\n",
    "| 4. Modelling | Build classification and clustering models | 5Ô∏è‚É£ 6Ô∏è‚É£ |\n",
    "| 5. Evaluation | Assess model performance | 7Ô∏è‚É£ |\n",
    "| 6. Deployment | Recommendations for implementation | 8Ô∏è‚É£ |\n",
    "\n",
    "**Prerequisite:** Run `Create_Mega_Table.ipynb` first to generate `oulad_mega_table.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, classification_report, confusion_matrix,\n",
    "                             roc_curve, silhouette_score, davies_bouldin_score)\n",
    "\n",
    "# Scipy for statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"‚úì All libraries loaded successfully!\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ Phase 1: Business Understanding\n",
    "\n",
    "## 2.1 Business Context\n",
    "\n",
    "The **Open University (OU)** is the largest university in the UK for undergraduate education, with a focus on distance learning. The university faces challenges with:\n",
    "- **High dropout rates** in online courses\n",
    "- **Late identification** of struggling students\n",
    "- **Limited resources** for personalized intervention\n",
    "\n",
    "## 2.2 Business Objectives\n",
    "\n",
    "1. **Identify at-risk students early** (within first 2-4 weeks) for timely intervention\n",
    "2. **Understand engagement patterns** that differentiate successful vs unsuccessful students\n",
    "3. **Segment students** into groups for targeted support strategies\n",
    "\n",
    "## 2.3 Data Mining Goals\n",
    "\n",
    "| Task | Type | Goal | Success Metric |\n",
    "|------|------|------|----------------|\n",
    "| Task 1 | Classification | Predict Pass/Distinction vs Fail/Withdrawn | AUC-ROC > 0.75, Accuracy > 70% |\n",
    "| Task 2 | Clustering | Segment students into meaningful groups | Silhouette Score > 0.2 |\n",
    "\n",
    "## 2.4 Success Criteria\n",
    "\n",
    "- Model can identify at-risk students with **>75% AUC-ROC**\n",
    "- Early engagement features (first 2 weeks) have **predictive power**\n",
    "- Clusters are **interpretable** and map to distinct outcomes\n",
    "- Recommendations are **actionable** for university staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ Phase 2: Data Understanding\n",
    "\n",
    "This phase involves thorough exploration of the data to understand its structure, quality, and characteristics.\n",
    "\n",
    "## 3.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD THE MEGA TABLE\n",
    "# =============================================================================\n",
    "# The mega table was created by merging all 7 OULAD tables\n",
    "# Each row represents ONE STUDENT enrolled in ONE MODULE PRESENTATION\n",
    "# =============================================================================\n",
    "\n",
    "# UPDATE THIS PATH if your file is in a different location\n",
    "DATA_PATH = 'oulad_mega_table.csv'\n",
    "\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"‚úì Data loaded successfully!\")\n",
    "print(f\"\\nüìä Dataset Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nüìå Each row = one student's enrollment in one module\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIRST LOOK AT THE DATA\n",
    "# =============================================================================\n",
    "# .head() shows the first 5 rows to understand data structure\n",
    "# =============================================================================\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(\"-\" * 60)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LIST ALL COLUMNS\n",
    "# =============================================================================\n",
    "# Understanding what variables we have available\n",
    "# =============================================================================\n",
    "\n",
    "print(\"All columns in the mega table:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    print(f\"{i:2}. {col} ({dtype})\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total: {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA TYPES SUMMARY\n",
    "# =============================================================================\n",
    "# Checking which columns are numerical vs categorical\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Data types summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Separate numerical and categorical\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerical columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MISSING VALUES ANALYSIS\n",
    "# =============================================================================\n",
    "# Identifying which columns have missing data and how much\n",
    "# This is crucial for deciding imputation strategies\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "missing = df.isna().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct,\n",
    "    'Data Type': df.dtypes\n",
    "})\n",
    "\n",
    "# Show only columns with missing values, sorted by count\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"\\n‚ö†Ô∏è {len(missing_df)} columns have missing values\")\n",
    "    print(\"\\nüìù Interpretation:\")\n",
    "    print(\"   - Missing VLE data = students who never accessed the VLE (fill with 0)\")\n",
    "    print(\"   - Missing assessment data = students who didn't submit (fill with 0)\")\n",
    "    print(\"   - Missing imd_band = unknown socioeconomic status (create indicator)\")\n",
    "else:\n",
    "    print(\"‚úì No missing values found!\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE MISSING VALUES\n",
    "# =============================================================================\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_df['Missing %'].head(15).plot(kind='barh', color='coral')\n",
    "    plt.xlabel('Missing Percentage (%)')\n",
    "    plt.title('Top 15 Columns with Missing Values', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Duplicate Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHECK FOR DUPLICATE ROWS\n",
    "# =============================================================================\n",
    "# Duplicates can skew analysis and model training\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Duplicate Rows Check:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "n_duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {n_duplicates}\")\n",
    "\n",
    "if n_duplicates > 0:\n",
    "    print(f\"‚ö†Ô∏è {n_duplicates} duplicates found ({n_duplicates/len(df)*100:.2f}%)\")\n",
    "    print(\"   These will be removed during data preparation.\")\n",
    "else:\n",
    "    print(\"‚úì No duplicate rows found\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TARGET VARIABLE: final_result\n",
    "# =============================================================================\n",
    "# This is what we want to predict\n",
    "# Four categories: Pass, Distinction, Fail, Withdrawn\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Target Variable Analysis (final_result):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "target_counts = df['final_result'].value_counts()\n",
    "target_pct = df['final_result'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Distribution:\")\n",
    "for result in target_counts.index:\n",
    "    print(f\"  {result}: {target_counts[result]:,} ({target_pct[result]:.1f}%)\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nüìä Success (Pass + Distinction): {target_pct.get('Pass', 0) + target_pct.get('Distinction', 0):.1f}%\")\n",
    "print(f\"üìä Failure (Fail + Withdrawn): {target_pct.get('Fail', 0) + target_pct.get('Withdrawn', 0):.1f}%\")\n",
    "print(\"\\n‚ö†Ô∏è Class imbalance detected - will use stratified sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE TARGET DISTRIBUTION\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Color scheme: green for success, red/gray for failure\n",
    "colors = {'Pass': '#2ecc71', 'Distinction': '#3498db', 'Fail': '#e74c3c', 'Withdrawn': '#95a5a6'}\n",
    "order = ['Pass', 'Distinction', 'Fail', 'Withdrawn']\n",
    "color_list = [colors[o] for o in order]\n",
    "\n",
    "# Bar chart\n",
    "target_counts.reindex(order).plot(kind='bar', ax=axes[0], color=color_list, edgecolor='black')\n",
    "axes[0].set_title('Final Results Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Final Result')\n",
    "axes[0].set_ylabel('Number of Students')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(target_counts.reindex(order)):\n",
    "    axes[0].text(i, v + 200, f'{v:,}', ha='center', fontsize=10)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(target_counts.reindex(order), labels=order, autopct='%1.1f%%', \n",
    "            colors=color_list, startangle=90, explode=[0.02]*4)\n",
    "axes[1].set_title('Final Results Proportion', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Numerical Variables: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY STATISTICS FOR NUMERICAL VARIABLES\n",
    "# =============================================================================\n",
    "# .describe() provides count, mean, std, min, 25%, 50%, 75%, max\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Summary Statistics (Numerical Variables):\")\n",
    "print(\"-\" * 60)\n",
    "df.describe().T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Distribution Analysis (Histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DISTRIBUTION OF KEY NUMERICAL VARIABLES\n",
    "# =============================================================================\n",
    "# Histograms help us understand:\n",
    "# - Shape of distribution (normal, skewed, bimodal)\n",
    "# - Presence of outliers\n",
    "# - Need for transformation\n",
    "# =============================================================================\n",
    "\n",
    "# Select key variables to visualize\n",
    "key_vars = ['vle_total_clicks', 'vle_active_days', 'assess_score_mean', \n",
    "            'vle_early_clicks', 'studied_credits', 'num_of_prev_attempts']\n",
    "key_vars = [v for v in key_vars if v in df.columns]\n",
    "\n",
    "print(\"Distribution of Key Variables:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    df[var].hist(bins=50, ax=ax, color='steelblue', edgecolor='black', alpha=0.7, density=True)\n",
    "    df[var].plot(kind='kde', ax=ax, color='red', linewidth=2)\n",
    "    \n",
    "    # Calculate skewness\n",
    "    skewness = df[var].skew()\n",
    "    \n",
    "    ax.set_title(f'{var}\\n(Skewness: {skewness:.2f})', fontweight='bold')\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel('Density')\n",
    "    \n",
    "    # Add interpretation\n",
    "    if abs(skewness) > 1:\n",
    "        ax.annotate('Highly skewed', xy=(0.7, 0.9), xycoords='axes fraction', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìù Interpretation:\")\n",
    "print(\"   - Skewness > 1: Right-skewed (long tail to the right)\")\n",
    "print(\"   - Skewness < -1: Left-skewed (long tail to the left)\")\n",
    "print(\"   - |Skewness| < 0.5: Approximately symmetric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Skewness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SKEWNESS ANALYSIS FOR ALL NUMERICAL COLUMNS\n",
    "# =============================================================================\n",
    "# Skewness measures asymmetry of the distribution\n",
    "# Highly skewed variables may need transformation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Skewness Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "skewness = df[numerical_cols].skew().sort_values(ascending=False)\n",
    "\n",
    "print(\"Most positively skewed (right-tailed):\")\n",
    "for var, skew in skewness.head(5).items():\n",
    "    print(f\"  {var}: {skew:.2f}\")\n",
    "\n",
    "print(\"\\nMost negatively skewed (left-tailed):\")\n",
    "for var, skew in skewness.tail(5).items():\n",
    "    print(f\"  {var}: {skew:.2f}\")\n",
    "\n",
    "# Count highly skewed\n",
    "highly_skewed = (skewness.abs() > 1).sum()\n",
    "print(f\"\\n‚ö†Ô∏è {highly_skewed} variables are highly skewed (|skewness| > 1)\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OUTLIER DETECTION USING IQR METHOD\n",
    "# =============================================================================\n",
    "# IQR (Interquartile Range) method:\n",
    "# - Q1 = 25th percentile, Q3 = 75th percentile\n",
    "# - IQR = Q3 - Q1\n",
    "# - Outliers: values < Q1 - 1.5*IQR or > Q3 + 1.5*IQR\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Outlier Detection (IQR Method):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def count_outliers_iqr(series):\n",
    "    \"\"\"Count outliers using IQR method\"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((series < lower_bound) | (series > upper_bound)).sum()\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "outlier_results = []\n",
    "for col in key_vars:\n",
    "    n_outliers, lb, ub = count_outliers_iqr(df[col].dropna())\n",
    "    pct = n_outliers / len(df) * 100\n",
    "    outlier_results.append({\n",
    "        'Variable': col,\n",
    "        'Outliers': n_outliers,\n",
    "        'Percentage': f'{pct:.1f}%',\n",
    "        'Lower Bound': f'{lb:.1f}',\n",
    "        'Upper Bound': f'{ub:.1f}'\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_results)\n",
    "print(outlier_df.to_string(index=False))\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE OUTLIERS WITH BOX PLOTS\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    ax = axes[i]\n",
    "    df.boxplot(column=var, ax=ax)\n",
    "    ax.set_title(f'{var}', fontweight='bold')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "plt.suptitle('Box Plots Showing Outliers', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìù Box Plot Interpretation:\")\n",
    "print(\"   - Box: 25th to 75th percentile (IQR)\")\n",
    "print(\"   - Line in box: Median (50th percentile)\")\n",
    "print(\"   - Whiskers: 1.5 √ó IQR from box\")\n",
    "print(\"   - Points beyond whiskers: Outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Categorical Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATEGORICAL VARIABLES DISTRIBUTION\n",
    "# =============================================================================\n",
    "\n",
    "cat_vars = ['gender', 'age_band', 'highest_education', 'imd_band', 'disability', 'region']\n",
    "cat_vars = [v for v in cat_vars if v in df.columns]\n",
    "\n",
    "print(\"Categorical Variables Distribution:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for var in cat_vars:\n",
    "    print(f\"\\n{var}:\")\n",
    "    print(df[var].value_counts())\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE CATEGORICAL VARIABLES\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(cat_vars[:6]):\n",
    "    ax = axes[i]\n",
    "    df[var].value_counts().plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "    ax.set_title(f'{var} Distribution', fontweight='bold')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 Feature Relationships with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NUMERICAL FEATURES VS TARGET\n",
    "# =============================================================================\n",
    "# Box plots showing how feature distributions differ by outcome\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Feature Distributions by Outcome:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    ax = axes[i]\n",
    "    order = ['Pass', 'Distinction', 'Fail', 'Withdrawn']\n",
    "    df.boxplot(column=var, by='final_result', ax=ax, positions=[1, 2, 3, 4])\n",
    "    ax.set_title(f'{var} by Outcome', fontweight='bold')\n",
    "    ax.set_xlabel('Final Result')\n",
    "    ax.set_ylabel(var)\n",
    "    plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìù Observation: Students who Pass/Distinction tend to have higher VLE engagement and assessment scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATEGORICAL FEATURES VS TARGET (Stacked Bar Charts)\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(cat_vars[:6]):\n",
    "    ax = axes[i]\n",
    "    ct = pd.crosstab(df[var], df['final_result'], normalize='index') * 100\n",
    "    order = [c for c in ['Pass', 'Distinction', 'Fail', 'Withdrawn'] if c in ct.columns]\n",
    "    ct[order].plot(kind='bar', stacked=True, ax=ax,\n",
    "                   color=['#2ecc71', '#3498db', '#e74c3c', '#95a5a6'])\n",
    "    ax.set_title(f'Outcome by {var}', fontweight='bold')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 Scatter Plots (Feature Relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SCATTER PLOTS BETWEEN KEY FEATURES\n",
    "# =============================================================================\n",
    "# Scatter plots help identify:\n",
    "# - Linear relationships between variables\n",
    "# - Clusters or patterns\n",
    "# - Outliers\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Scatter Plots Between Key Features:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create binary target for coloring\n",
    "df['target_binary'] = df['final_result'].apply(lambda x: 1 if x in ['Pass', 'Distinction'] else 0)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Total clicks vs Active days\n",
    "ax = axes[0, 0]\n",
    "scatter = ax.scatter(df['vle_active_days'], df['vle_total_clicks'], \n",
    "                     c=df['target_binary'], cmap='RdYlGn', alpha=0.3, s=10)\n",
    "ax.set_xlabel('VLE Active Days')\n",
    "ax.set_ylabel('VLE Total Clicks')\n",
    "ax.set_title('Total Clicks vs Active Days', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Success (1=Pass/Dist)')\n",
    "\n",
    "# Plot 2: Assessment score vs Total clicks\n",
    "ax = axes[0, 1]\n",
    "scatter = ax.scatter(df['vle_total_clicks'], df['assess_score_mean'], \n",
    "                     c=df['target_binary'], cmap='RdYlGn', alpha=0.3, s=10)\n",
    "ax.set_xlabel('VLE Total Clicks')\n",
    "ax.set_ylabel('Assessment Score Mean')\n",
    "ax.set_title('Assessment Score vs Total Clicks', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Success (1=Pass/Dist)')\n",
    "\n",
    "# Plot 3: Early clicks vs Total clicks\n",
    "if 'vle_early_clicks' in df.columns:\n",
    "    ax = axes[1, 0]\n",
    "    scatter = ax.scatter(df['vle_early_clicks'], df['vle_total_clicks'], \n",
    "                         c=df['target_binary'], cmap='RdYlGn', alpha=0.3, s=10)\n",
    "    ax.set_xlabel('VLE Early Clicks (First 2 Weeks)')\n",
    "    ax.set_ylabel('VLE Total Clicks')\n",
    "    ax.set_title('Early Engagement vs Total Engagement', fontweight='bold')\n",
    "    plt.colorbar(scatter, ax=ax, label='Success (1=Pass/Dist)')\n",
    "\n",
    "# Plot 4: Assessment score vs Active days\n",
    "ax = axes[1, 1]\n",
    "scatter = ax.scatter(df['vle_active_days'], df['assess_score_mean'], \n",
    "                     c=df['target_binary'], cmap='RdYlGn', alpha=0.3, s=10)\n",
    "ax.set_xlabel('VLE Active Days')\n",
    "ax.set_ylabel('Assessment Score Mean')\n",
    "ax.set_title('Assessment Score vs Active Days', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Success (1=Pass/Dist)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìù Observations:\")\n",
    "print(\"   - Green points (success) cluster in high-engagement regions\")\n",
    "print(\"   - Red points (failure) cluster in low-engagement regions\")\n",
    "print(\"   - Clear separation suggests these features have predictive power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CORRELATION MATRIX\n",
    "# =============================================================================\n",
    "# Correlation measures linear relationship between variables\n",
    "# Range: -1 (perfect negative) to +1 (perfect positive)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Correlation Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Select numerical columns for correlation\n",
    "corr_cols = key_vars + ['target_binary']\n",
    "corr_cols = [c for c in corr_cols if c in df.columns]\n",
    "\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix (Key Variables)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìù Correlation Interpretation:\")\n",
    "print(\"   - |r| > 0.7: Strong correlation\")\n",
    "print(\"   - |r| 0.4-0.7: Moderate correlation\")\n",
    "print(\"   - |r| < 0.4: Weak correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CORRELATION WITH TARGET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Correlation with Target (Success):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Get all numerical columns\n",
    "all_numerical = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "all_numerical = [c for c in all_numerical if c != 'target_binary' and c != 'id_student']\n",
    "\n",
    "target_corr = df[all_numerical + ['target_binary']].corr()['target_binary'].drop('target_binary')\n",
    "target_corr_sorted = target_corr.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 15 features correlated with success:\")\n",
    "for i, (feat, corr) in enumerate(target_corr_sorted.head(15).items(), 1):\n",
    "    direction = '+' if target_corr[feat] > 0 else '-'\n",
    "    print(f\"  {i:2}. {feat}: {direction}{corr:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 Analysis by Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANALYSIS BY MODULE\n",
    "# =============================================================================\n",
    "# Do patterns differ across modules?\n",
    "# =============================================================================\n",
    "\n",
    "if 'code_module' in df.columns:\n",
    "    print(\"Success Rate by Module:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    module_stats = df.groupby('code_module').agg({\n",
    "        'target_binary': ['mean', 'count'],\n",
    "        'vle_total_clicks': 'mean',\n",
    "        'assess_score_mean': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    module_stats.columns = ['Success Rate', 'N Students', 'Avg Clicks', 'Avg Score']\n",
    "    module_stats['Success Rate'] = (module_stats['Success Rate'] * 100).round(1).astype(str) + '%'\n",
    "    print(module_stats)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.15 Data Understanding Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA UNDERSTANDING SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"                    DATA UNDERSTANDING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä DATASET OVERVIEW\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ Rows: {df.shape[0]:,} (student-module enrollments)\n",
    "‚Ä¢ Columns: {df.shape[1]}\n",
    "‚Ä¢ Numerical features: {len(numerical_cols)}\n",
    "‚Ä¢ Categorical features: {len(categorical_cols)}\n",
    "\n",
    "üéØ TARGET VARIABLE (final_result)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ Pass: {target_pct.get('Pass', 0):.1f}%\n",
    "‚Ä¢ Distinction: {target_pct.get('Distinction', 0):.1f}%\n",
    "‚Ä¢ Fail: {target_pct.get('Fail', 0):.1f}%\n",
    "‚Ä¢ Withdrawn: {target_pct.get('Withdrawn', 0):.1f}%\n",
    "‚Ä¢ Class imbalance: YES (need stratified sampling)\n",
    "\n",
    "‚ö†Ô∏è DATA QUALITY ISSUES\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ Missing values: {len(missing_df)} columns affected\n",
    "‚Ä¢ Duplicate rows: {n_duplicates}\n",
    "‚Ä¢ Highly skewed variables: {highly_skewed}\n",
    "‚Ä¢ Outliers: Present in engagement metrics\n",
    "\n",
    "üìà KEY FINDINGS\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ VLE engagement strongly correlates with success\n",
    "‚Ä¢ Assessment scores strongly correlate with success\n",
    "‚Ä¢ Early engagement (first 2 weeks) shows predictive potential\n",
    "‚Ä¢ Clear separation between success/failure in scatter plots\n",
    "\n",
    "üìù IMPLICATIONS FOR DATA PREPARATION\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ Fill missing VLE/assessment with 0 (no activity)\n",
    "‚Ä¢ Create missing indicator for imd_band\n",
    "‚Ä¢ Consider outlier handling (capping)\n",
    "‚Ä¢ Engineer new features (ratios, bins)\n",
    "‚Ä¢ Encode categorical variables\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Phase 3: Data Preparation\n",
    "\n",
    "This phase transforms raw data into a clean, analysis-ready format.\n",
    "\n",
    "## 4.1 Create Working Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE WORKING COPY\n",
    "# =============================================================================\n",
    "# Always work on a copy to preserve original data\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 1: Create working copy\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df_prep = df.copy()\n",
    "print(f\"‚úì Created copy: {df_prep.shape[0]:,} rows √ó {df_prep.shape[1]} columns\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HANDLE MISSING VALUES\n",
    "# =============================================================================\n",
    "# Strategy:\n",
    "# 1. imd_band: Create missing indicator, then fill with 'Unknown'\n",
    "# 2. VLE columns: Fill with 0 (no activity)\n",
    "# 3. Assessment columns: Fill with 0 (no submissions)\n",
    "# 4. Remaining numerical: Impute with median\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 2: Handle missing values\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 2a. Create missing indicator for imd_band (as taught in class)\n",
    "if 'imd_band' in df_prep.columns:\n",
    "    df_prep['imd_band_missing'] = df_prep['imd_band'].isna().astype(int)\n",
    "    df_prep['imd_band'] = df_prep['imd_band'].fillna('Unknown')\n",
    "    print(\"‚úì imd_band: Created missing indicator, filled with 'Unknown'\")\n",
    "\n",
    "# 2b. Fill VLE columns with 0\n",
    "vle_cols = [c for c in df_prep.columns if c.startswith('vle_')]\n",
    "df_prep[vle_cols] = df_prep[vle_cols].fillna(0)\n",
    "print(f\"‚úì VLE columns ({len(vle_cols)}): Filled with 0\")\n",
    "\n",
    "# 2c. Fill assessment columns with 0\n",
    "assess_cols = [c for c in df_prep.columns if c.startswith('assess_')]\n",
    "df_prep[assess_cols] = df_prep[assess_cols].fillna(0)\n",
    "print(f\"‚úì Assessment columns ({len(assess_cols)}): Filled with 0\")\n",
    "\n",
    "# 2d. Impute remaining numerical with median using SimpleImputer\n",
    "num_cols_remaining = df_prep.select_dtypes(include=[np.number]).columns\n",
    "cols_with_na = [c for c in num_cols_remaining if df_prep[c].isna().any()]\n",
    "\n",
    "if cols_with_na:\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df_prep[cols_with_na] = imputer.fit_transform(df_prep[cols_with_na])\n",
    "    print(f\"‚úì Remaining numerical ({len(cols_with_na)}): Imputed with median\")\n",
    "\n",
    "print(f\"\\n‚úì Remaining missing values: {df_prep.isna().sum().sum()}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HANDLE OUTLIERS (CAPPING)\n",
    "# =============================================================================\n",
    "# Strategy: Cap extreme values at 99th percentile\n",
    "# This preserves information while reducing impact of extreme outliers\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 3: Handle outliers (capping at 99th percentile)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Columns to cap (engagement metrics with extreme outliers)\n",
    "cols_to_cap = ['vle_total_clicks', 'vle_active_days', 'vle_early_clicks', 'vle_unique_resources']\n",
    "cols_to_cap = [c for c in cols_to_cap if c in df_prep.columns]\n",
    "\n",
    "for col in cols_to_cap:\n",
    "    p99 = df_prep[col].quantile(0.99)\n",
    "    n_capped = (df_prep[col] > p99).sum()\n",
    "    df_prep[col] = df_prep[col].clip(upper=p99)\n",
    "    print(f\"‚úì {col}: Capped {n_capped} values at {p99:.0f}\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Feature Engineering - Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING: RATIO FEATURES\n",
    "# =============================================================================\n",
    "# Create new features by combining existing ones\n",
    "# Ratios often capture meaningful patterns\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 4: Feature Engineering - Ratio Features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Clicks per active day (engagement intensity)\n",
    "df_prep['clicks_per_day'] = df_prep['vle_total_clicks'] / df_prep['vle_active_days'].replace(0, 1)\n",
    "print(\"‚úì Created: clicks_per_day (total_clicks / active_days)\")\n",
    "\n",
    "# Score per assessment (average performance)\n",
    "if 'assess_count' in df_prep.columns and 'assess_score_mean' in df_prep.columns:\n",
    "    df_prep['assessments_completed'] = df_prep['assess_count']\n",
    "    print(\"‚úì Created: assessments_completed\")\n",
    "\n",
    "# Early engagement ratio (proportion of total engagement that happened early)\n",
    "if 'vle_early_clicks' in df_prep.columns:\n",
    "    df_prep['early_engagement_ratio'] = df_prep['vle_early_clicks'] / df_prep['vle_total_clicks'].replace(0, 1)\n",
    "    print(\"‚úì Created: early_engagement_ratio (early_clicks / total_clicks)\")\n",
    "\n",
    "# Resources per active day\n",
    "if 'vle_unique_resources' in df_prep.columns:\n",
    "    df_prep['resources_per_day'] = df_prep['vle_unique_resources'] / df_prep['vle_active_days'].replace(0, 1)\n",
    "    print(\"‚úì Created: resources_per_day\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING: BINARY FLAGS\n",
    "# =============================================================================\n",
    "# Create yes/no indicators for specific conditions\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 5: Feature Engineering - Binary Flags\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Is active early? (any engagement in first 2 weeks)\n",
    "if 'vle_early_clicks' in df_prep.columns:\n",
    "    df_prep['is_active_early'] = (df_prep['vle_early_clicks'] > 0).astype(int)\n",
    "    print(\"‚úì Created: is_active_early (1 if any early clicks, 0 otherwise)\")\n",
    "\n",
    "# Registered early? (before course start)\n",
    "if 'date_registration' in df_prep.columns:\n",
    "    df_prep['registered_early'] = (df_prep['date_registration'] < 0).astype(int)\n",
    "    print(\"‚úì Created: registered_early (1 if registered before day 0)\")\n",
    "\n",
    "# Has submitted any assessment?\n",
    "if 'assess_count' in df_prep.columns:\n",
    "    df_prep['has_submitted'] = (df_prep['assess_count'] > 0).astype(int)\n",
    "    print(\"‚úì Created: has_submitted (1 if any assessments submitted)\")\n",
    "\n",
    "# High performer? (average score > 70)\n",
    "if 'assess_score_mean' in df_prep.columns:\n",
    "    df_prep['is_high_performer'] = (df_prep['assess_score_mean'] >= 70).astype(int)\n",
    "    print(\"‚úì Created: is_high_performer (1 if avg score >= 70)\")\n",
    "\n",
    "# Has previous attempts?\n",
    "if 'num_of_prev_attempts' in df_prep.columns:\n",
    "    df_prep['has_prev_attempts'] = (df_prep['num_of_prev_attempts'] > 0).astype(int)\n",
    "    print(\"‚úì Created: has_prev_attempts\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Feature Engineering - Binning with pd.cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING: BINNING WITH pd.cut()\n",
    "# =============================================================================\n",
    "# Convert continuous variables into categorical bins\n",
    "# This can capture non-linear relationships\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 6: Feature Engineering - Binning with pd.cut()\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Engagement level bins (based on total clicks)\n",
    "df_prep['engagement_level'] = pd.cut(\n",
    "    df_prep['vle_total_clicks'],\n",
    "    bins=[0, 100, 500, 1000, 2000, float('inf')],\n",
    "    labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'],\n",
    "    include_lowest=True\n",
    ")\n",
    "print(\"‚úì Created: engagement_level (binned total_clicks)\")\n",
    "print(f\"   Distribution: {df_prep['engagement_level'].value_counts().to_dict()}\")\n",
    "\n",
    "# Score level bins\n",
    "df_prep['score_level'] = pd.cut(\n",
    "    df_prep['assess_score_mean'],\n",
    "    bins=[0, 40, 60, 70, 80, 100],\n",
    "    labels=['Failing', 'Poor', 'Average', 'Good', 'Excellent'],\n",
    "    include_lowest=True\n",
    ")\n",
    "print(\"\\n‚úì Created: score_level (binned assess_score_mean)\")\n",
    "print(f\"   Distribution: {df_prep['score_level'].value_counts().to_dict()}\")\n",
    "\n",
    "# Active days bins\n",
    "df_prep['activity_level'] = pd.cut(\n",
    "    df_prep['vle_active_days'],\n",
    "    bins=[0, 10, 30, 60, 100, float('inf')],\n",
    "    labels=['Minimal', 'Low', 'Moderate', 'Regular', 'Intensive'],\n",
    "    include_lowest=True\n",
    ")\n",
    "print(\"\\n‚úì Created: activity_level (binned active_days)\")\n",
    "print(f\"   Distribution: {df_prep['activity_level'].value_counts().to_dict()}\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE BINNED FEATURES VS OUTCOME\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "binned_features = ['engagement_level', 'score_level', 'activity_level']\n",
    "\n",
    "for i, feat in enumerate(binned_features):\n",
    "    ax = axes[i]\n",
    "    ct = pd.crosstab(df_prep[feat], df_prep['final_result'], normalize='index') * 100\n",
    "    order = [c for c in ['Pass', 'Distinction', 'Fail', 'Withdrawn'] if c in ct.columns]\n",
    "    ct[order].plot(kind='bar', stacked=True, ax=ax,\n",
    "                   color=['#2ecc71', '#3498db', '#e74c3c', '#95a5a6'])\n",
    "    ax.set_title(f'Outcome by {feat}', fontweight='bold')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìù Observation: Clear relationship between engagement/score levels and outcomes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Feature Engineering - Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING: INTERACTION FEATURES\n",
    "# =============================================================================\n",
    "# Combine features to capture combined effects\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 7: Feature Engineering - Interaction Features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Engagement √ó Score (comprehensive performance)\n",
    "df_prep['engagement_score_product'] = df_prep['vle_total_clicks'] * df_prep['assess_score_mean'] / 1000\n",
    "print(\"‚úì Created: engagement_score_product (clicks √ó score / 1000)\")\n",
    "\n",
    "# Early engagement √ó has submitted\n",
    "if 'vle_early_clicks' in df_prep.columns and 'has_submitted' in df_prep.columns:\n",
    "    df_prep['early_submission_indicator'] = df_prep['vle_early_clicks'] * df_prep['has_submitted']\n",
    "    print(\"‚úì Created: early_submission_indicator (early_clicks √ó has_submitted)\")\n",
    "\n",
    "# Active days √ó Score\n",
    "df_prep['consistency_score'] = df_prep['vle_active_days'] * df_prep['assess_score_mean'] / 100\n",
    "print(\"‚úì Created: consistency_score (active_days √ó score / 100)\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENCODE CATEGORICAL VARIABLES\n",
    "# =============================================================================\n",
    "# Strategy:\n",
    "# 1. One-hot encoding for nominal categories (no order)\n",
    "# 2. Ordinal encoding for ordered categories\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 8: Encode categorical variables\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 8a. One-hot encoding for nominal variables (using pd.get_dummies with drop_first=True)\n",
    "nominal_cols = ['gender', 'disability']\n",
    "for col in nominal_cols:\n",
    "    if col in df_prep.columns:\n",
    "        dummies = pd.get_dummies(df_prep[col], prefix=col, drop_first=True)\n",
    "        df_prep = pd.concat([df_prep, dummies], axis=1)\n",
    "        print(f\"‚úì One-hot encoded: {col} ‚Üí {list(dummies.columns)}\")\n",
    "\n",
    "# 8b. Ordinal encoding for education (has natural order)\n",
    "education_order = {\n",
    "    'No Formal quals': 0,\n",
    "    'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2,\n",
    "    'HE Qualification': 3,\n",
    "    'Post Graduate Qualification': 4\n",
    "}\n",
    "if 'highest_education' in df_prep.columns:\n",
    "    df_prep['education_level'] = df_prep['highest_education'].map(education_order)\n",
    "    print(f\"‚úì Ordinal encoded: highest_education ‚Üí education_level\")\n",
    "\n",
    "# 8c. Ordinal encoding for age band\n",
    "age_order = {'0-35': 0, '35-55': 1, '55<=': 2}\n",
    "if 'age_band' in df_prep.columns:\n",
    "    df_prep['age_level'] = df_prep['age_band'].map(age_order)\n",
    "    print(f\"‚úì Ordinal encoded: age_band ‚Üí age_level\")\n",
    "\n",
    "# 8d. Ordinal encoding for binned features\n",
    "engagement_order = {'Very Low': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very High': 4}\n",
    "df_prep['engagement_level_encoded'] = df_prep['engagement_level'].map(engagement_order)\n",
    "print(f\"‚úì Ordinal encoded: engagement_level ‚Üí engagement_level_encoded\")\n",
    "\n",
    "score_order = {'Failing': 0, 'Poor': 1, 'Average': 2, 'Good': 3, 'Excellent': 4}\n",
    "df_prep['score_level_encoded'] = df_prep['score_level'].map(score_order)\n",
    "print(f\"‚úì Ordinal encoded: score_level ‚Üí score_level_encoded\")\n",
    "\n",
    "activity_order = {'Minimal': 0, 'Low': 1, 'Moderate': 2, 'Regular': 3, 'Intensive': 4}\n",
    "df_prep['activity_level_encoded'] = df_prep['activity_level'].map(activity_order)\n",
    "print(f\"‚úì Ordinal encoded: activity_level ‚Üí activity_level_encoded\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Create Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE BINARY TARGET VARIABLE\n",
    "# =============================================================================\n",
    "# 1 = Success (Pass or Distinction)\n",
    "# 0 = Failure (Fail or Withdrawn)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 9: Create target variable\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df_prep['target'] = df_prep['final_result'].apply(\n",
    "    lambda x: 1 if x in ['Pass', 'Distinction'] else 0\n",
    ")\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(df_prep['target'].value_counts())\n",
    "print(f\"\\nSuccess rate: {df_prep['target'].mean()*100:.1f}%\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IDENTIFY ALL CANDIDATE FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 10: Identify candidate features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Columns to EXCLUDE from features\n",
    "exclude_cols = [\n",
    "    'id_student', 'student_module_key', 'code_module', 'code_presentation',\n",
    "    'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability',\n",
    "    'final_result', 'target', 'target_binary',\n",
    "    'date_registration', 'date_unregistration',\n",
    "    'engagement_level', 'score_level', 'activity_level'  # Keep only encoded versions\n",
    "]\n",
    "\n",
    "# Get all numerical columns as candidates\n",
    "candidate_features = [col for col in df_prep.columns \n",
    "                      if col not in exclude_cols \n",
    "                      and df_prep[col].dtype in ['int64', 'float64', 'int32', 'float32', 'uint8', 'bool']]\n",
    "\n",
    "print(f\"Total candidate features: {len(candidate_features)}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECT TOP K FEATURES BY CORRELATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 11: Select top K features by correlation with target\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = df_prep[candidate_features + ['target']].corr()['target'].drop('target')\n",
    "correlations_abs = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 features by |correlation| with target:\")\n",
    "for i, (feat, corr) in enumerate(correlations_abs.head(20).items(), 1):\n",
    "    direction = '+' if correlations[feat] > 0 else '-'\n",
    "    print(f\"  {i:2}. {feat}: {direction}{corr:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECT FINAL FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "K = 15  # Number of features to use (adjustable)\n",
    "\n",
    "selected_features = correlations_abs.head(K).index.tolist()\n",
    "\n",
    "print(f\"\\n‚úì SELECTED TOP {K} FEATURES FOR MODELLING:\")\n",
    "print(\"=\" * 60)\n",
    "for i, feat in enumerate(selected_features, 1):\n",
    "    corr = correlations[feat]\n",
    "    print(f\"  {i:2}. {feat} (r = {corr:+.4f})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE SELECTED FEATURES CORRELATION\n",
    "# =============================================================================\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df_prep[selected_features + ['target']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f', square=True)\n",
    "plt.title(f'Correlation Matrix (Selected {K} Features + Target)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE FINAL FEATURE MATRIX AND TARGET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 12: Create final dataset\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "X = df_prep[selected_features].copy()\n",
    "y = df_prep['target'].copy()\n",
    "\n",
    "# Handle any remaining infinities\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "print(f\"Feature matrix X: {X.shape[0]:,} rows √ó {X.shape[1]} features\")\n",
    "print(f\"Target vector y: {y.shape[0]:,} values\")\n",
    "print(f\"\\nFeatures: {selected_features}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 Data Preparation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PREPARATION SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"                    DATA PREPARATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä ORIGINAL DATA\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ Rows: {df.shape[0]:,}\n",
    "‚Ä¢ Columns: {df.shape[1]}\n",
    "\n",
    "üîß TRANSFORMATIONS APPLIED\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "1. Missing Values:\n",
    "   - Created imd_band_missing indicator\n",
    "   - Filled VLE/assessment with 0\n",
    "   - Imputed numerical with median\n",
    "\n",
    "2. Outlier Handling:\n",
    "   - Capped at 99th percentile\n",
    "\n",
    "3. Feature Engineering:\n",
    "   - Ratio features: clicks_per_day, early_engagement_ratio, resources_per_day\n",
    "   - Binary flags: is_active_early, registered_early, has_submitted, is_high_performer\n",
    "   - Binning: engagement_level, score_level, activity_level\n",
    "   - Interactions: engagement_score_product, consistency_score\n",
    "\n",
    "4. Encoding:\n",
    "   - One-hot: gender, disability\n",
    "   - Ordinal: education_level, age_level, binned features\n",
    "\n",
    "5. Feature Selection:\n",
    "   - Selected top {K} features by correlation\n",
    "\n",
    "üìà FINAL DATASET\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ Rows: {X.shape[0]:,}\n",
    "‚Ä¢ Features: {X.shape[1]}\n",
    "‚Ä¢ Target: Binary (1=Success, 0=Failure)\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ Phase 4: Modelling - Task 1 (Classification)\n",
    "\n",
    "## 5.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# =============================================================================\n",
    "# Stratified split to maintain class proportions in both sets\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 13: Train-test split (stratified)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"\\nTarget distribution (train):\")\n",
    "print(f\"  Success (1): {y_train.sum():,} ({y_train.mean()*100:.1f}%)\")\n",
    "print(f\"  Failure (0): {(y_train==0).sum():,} ({(1-y_train.mean())*100:.1f}%)\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE SCALING WITH StandardScaler\n",
    "# =============================================================================\n",
    "# Transforms features to have mean=0 and std=1\n",
    "# Important for: Logistic Regression, SVM, Neural Networks\n",
    "# Not needed for: Tree-based models (RF, GB)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 14: Feature scaling (StandardScaler)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úì Features scaled (mean=0, std=1)\")\n",
    "print(\"  Used for: Logistic Regression\")\n",
    "print(\"  Not needed for: Random Forest, Gradient Boosting\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAIN AND EVALUATE MULTIPLE MODELS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 15: Train and evaluate models\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    \n",
    "    # Use scaled data for Logistic, unscaled for tree models\n",
    "    if 'Logistic' in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úì Accuracy: {results[name]['Accuracy']:.4f}\")\n",
    "    print(f\"   ‚úì AUC-ROC:  {results[name]['AUC-ROC']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPARE MODEL PERFORMANCE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 16: Model comparison\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df.round(4))\n",
    "\n",
    "best_model_name = results_df['AUC-ROC'].idxmax()\n",
    "print(f\"\\nüèÜ Best model (by AUC-ROC): {best_model_name}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "results_df.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xticklabels(results_df.index, rotation=0)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Best Model Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DETAILED ANALYSIS OF BEST MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 17: Detailed analysis - Random Forest\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rf = models['Random Forest']\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, \n",
    "                            target_names=['Fail/Withdrawn', 'Pass/Distinction']))\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Fail/Withdrawn', 'Pass/Distinction'],\n",
    "            yticklabels=['Fail/Withdrawn', 'Pass/Distinction'])\n",
    "plt.title('Confusion Matrix - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"True Negatives (correct failures): {tn:,}\")\n",
    "print(f\"True Positives (correct successes): {tp:,}\")\n",
    "print(f\"False Positives (predicted success, was failure): {fp:,}\")\n",
    "print(f\"False Negatives (predicted failure, was success): {fn:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 18: Feature importance\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature importance ranking:\")\n",
    "for i, row in importance.iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Importance']:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(importance)), importance['Importance'], color='steelblue')\n",
    "plt.yticks(range(len(importance)), importance['Feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ROC CURVES COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 19: ROC curves\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "for (name, model), color in zip(models.items(), colors):\n",
    "    if 'Logistic' in name:\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})', color=color, linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.500)')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HYPERPARAMETER TUNING WITH GRIDSEARCHCV\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 20: Hyperparameter tuning (GridSearchCV)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "print(\"Parameter grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "print(\"\\nüîÑ Running GridSearchCV (this may take a few minutes)...\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úì Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"‚úì Best CV AUC-ROC: {grid_search.best_score_:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned model\n",
    "print(\"Tuned model performance on test set:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_tuned = best_rf.predict(X_test)\n",
    "y_proba_tuned = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"AUC-ROC:   {roc_auc_score(y_test, y_proba_tuned):.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CROSS-VALIDATION FOR ROBUST EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 21: 5-Fold Cross-Validation\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f\"CV AUC-ROC scores: {cv_scores.round(4)}\")\n",
    "print(f\"Mean: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std:  {cv_scores.std():.4f}\")\n",
    "print(f\"95% CI: [{cv_scores.mean() - 1.96*cv_scores.std():.4f}, {cv_scores.mean() + 1.96*cv_scores.std():.4f}]\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ Phase 4: Modelling - Task 2 (Clustering)\n",
    "\n",
    "## 6.1 Select Clustering Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECT FEATURES FOR CLUSTERING\n",
    "# =============================================================================\n",
    "# Use engagement-focused features to segment students by behavior\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 22: Select clustering features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cluster_features = [\n",
    "    'vle_total_clicks', 'vle_active_days', 'vle_unique_resources',\n",
    "    'assess_score_mean', 'assess_count', 'clicks_per_day'\n",
    "]\n",
    "cluster_features = [f for f in cluster_features if f in df_prep.columns]\n",
    "\n",
    "print(f\"Using {len(cluster_features)} features for clustering:\")\n",
    "for f in cluster_features:\n",
    "    print(f\"  - {f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and scale\n",
    "X_cluster = df_prep[cluster_features].fillna(0)\n",
    "X_cluster = X_cluster.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "print(f\"Clustering data: {X_cluster_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Find Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUATE DIFFERENT K VALUES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 23: Evaluate k values (2-10)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "K_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "db_scores = []\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_cluster_scaled, labels))\n",
    "    db_scores.append(davies_bouldin_score(X_cluster_scaled, labels))\n",
    "    print(f\"k={k}: Silhouette={silhouettes[-1]:.4f}, Davies-Bouldin={db_scores[-1]:.4f}\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2)\n",
    "axes[0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(K_range, silhouettes, 'go-', linewidth=2)\n",
    "axes[1].set_xlabel('Number of Clusters (k)')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette (higher = better)', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(K_range, db_scores, 'ro-', linewidth=2)\n",
    "axes[2].set_xlabel('Number of Clusters (k)')\n",
    "axes[2].set_ylabel('Davies-Bouldin Index')\n",
    "axes[2].set_title('Davies-Bouldin (lower = better)', fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Fit Final K-Means Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIT FINAL K-MEANS MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 24: Fit K-Means with optimal k\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "OPTIMAL_K = 4  # Based on elbow/silhouette analysis\n",
    "\n",
    "kmeans_final = KMeans(n_clusters=OPTIMAL_K, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans_final.fit_predict(X_cluster_scaled)\n",
    "\n",
    "df_prep['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"K-Means with k={OPTIMAL_K}:\")\n",
    "cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()\n",
    "for c, count in cluster_counts.items():\n",
    "    pct = count / len(cluster_labels) * 100\n",
    "    print(f\"  Cluster {c}: {count:,} students ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nSilhouette Score: {silhouette_score(X_cluster_scaled, cluster_labels):.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin_score(X_cluster_scaled, cluster_labels):.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Cluster Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROFILE EACH CLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 25: Cluster profiling\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "profiles = df_prep.groupby('cluster')[cluster_features].mean()\n",
    "print(\"Cluster centroids (mean values):\")\n",
    "print(profiles.round(2).T)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize profiles\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(cluster_features[:6]):\n",
    "    ax = axes[i]\n",
    "    df_prep.boxplot(column=feat, by='cluster', ax=ax)\n",
    "    ax.set_title(f'{feat} by Cluster', fontweight='bold')\n",
    "    ax.set_xlabel('Cluster')\n",
    "    plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Cluster vs Outcome Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLUSTER VS OUTCOME ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 26: Cluster vs outcome\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Crosstab\n",
    "crosstab = pd.crosstab(df_prep['cluster'], df_prep['final_result'], normalize='index') * 100\n",
    "print(\"Outcome distribution by cluster (%):\")\n",
    "print(crosstab.round(1))\n",
    "\n",
    "# Success rate\n",
    "success_rate = df_prep.groupby('cluster')['target'].mean() * 100\n",
    "print(\"\\nSuccess rate by cluster:\")\n",
    "for c, rate in success_rate.items():\n",
    "    risk = 'HIGH RISK' if rate < 50 else 'MEDIUM RISK' if rate < 70 else 'LOW RISK'\n",
    "    print(f\"  Cluster {c}: {rate:.1f}% - {risk}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked outcomes\n",
    "order = ['Pass', 'Distinction', 'Fail', 'Withdrawn']\n",
    "cols = [c for c in order if c in crosstab.columns]\n",
    "crosstab[cols].plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                    color=['#2ecc71', '#3498db', '#e74c3c', '#95a5a6'])\n",
    "axes[0].set_title('Outcomes by Cluster', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Percentage')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "axes[0].legend(title='Final Result')\n",
    "\n",
    "# Success rate\n",
    "colors = ['#e74c3c' if r < 50 else '#f39c12' if r < 70 else '#2ecc71' for r in success_rate]\n",
    "success_rate.plot(kind='bar', ax=axes[1], color=colors, edgecolor='black')\n",
    "axes[1].set_title('Success Rate by Cluster', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Success Rate (%)')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "axes[1].axhline(df_prep['target'].mean()*100, color='black', linestyle='--', label='Overall')\n",
    "axes[1].legend()\n",
    "\n",
    "for i, v in enumerate(success_rate):\n",
    "    axes[1].text(i, v + 1, f'{v:.0f}%', ha='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PCA VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 27: PCA visualization\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "print(f\"Variance explained: PC1={pca.explained_variance_ratio_[0]:.1%}, PC2={pca.explained_variance_ratio_[1]:.1%}\")\n",
    "print(f\"Total: {sum(pca.explained_variance_ratio_):.1%}\")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', alpha=0.5, s=10)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "\n",
    "# Centroids\n",
    "centers_pca = pca.transform(kmeans_final.cluster_centers_)\n",
    "plt.scatter(centers_pca[:, 0], centers_pca[:, 1], c='red', marker='X', s=300, \n",
    "            edgecolors='black', linewidths=2, label='Centroids')\n",
    "\n",
    "for i, (x, y_coord) in enumerate(centers_pca):\n",
    "    plt.annotate(f'C{i}', (x, y_coord), fontsize=12, fontweight='bold', ha='center', va='bottom', color='red')\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
    "plt.title('Student Clusters (PCA Visualization)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Cluster Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INTERPRET AND NAME CLUSTERS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 28: Cluster interpretation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for c in range(OPTIMAL_K):\n",
    "    profile = profiles.loc[c]\n",
    "    rate = success_rate[c]\n",
    "    count = cluster_counts[c]\n",
    "    \n",
    "    print(f\"\\nüîπ CLUSTER {c}\")\n",
    "    print(f\"   Size: {count:,} ({count/len(df_prep)*100:.1f}%)\")\n",
    "    print(f\"   Success Rate: {rate:.1f}%\")\n",
    "    print(f\"   Avg Clicks: {profile.get('vle_total_clicks', 0):.0f}\")\n",
    "    print(f\"   Avg Active Days: {profile.get('vle_active_days', 0):.0f}\")\n",
    "    print(f\"   Avg Score: {profile.get('assess_score_mean', 0):.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüìù Suggested cluster names (based on analysis):\")\n",
    "print(\"   Example names: 'Disengaged', 'Late Starters', 'High Achievers', 'Consistent Learners'\")\n",
    "print(\"   ‚ûú Update based on YOUR actual cluster profiles above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Phase 5: Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"                         EVALUATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"TASK 1: CLASSIFICATION (Predictive Model)\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Model: Random Forest (Tuned)\")\n",
    "print(f\"Features: {K} (selected by correlation)\")\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  ‚Ä¢ Accuracy:  {accuracy_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {precision_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:    {recall_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"  ‚Ä¢ F1 Score:  {f1_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"  ‚Ä¢ AUC-ROC:   {roc_auc_score(y_test, y_proba_tuned):.4f}\")\n",
    "\n",
    "print(f\"\\nCross-Validation (5-fold):\")\n",
    "print(f\"  ‚Ä¢ Mean AUC-ROC: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "\n",
    "print(f\"\\nTop 5 Predictive Features:\")\n",
    "for _, row in importance.head(5).iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"TASK 2: CLUSTERING (Segmentation Model)\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Algorithm: K-Means\")\n",
    "print(f\"Number of Clusters: {OPTIMAL_K}\")\n",
    "print(f\"Features: {len(cluster_features)}\")\n",
    "print(f\"Silhouette Score: {silhouette_score(X_cluster_scaled, cluster_labels):.4f}\")\n",
    "\n",
    "print(f\"\\nCluster Risk Levels:\")\n",
    "for c in range(OPTIMAL_K):\n",
    "    rate = success_rate[c]\n",
    "    risk = 'HIGH RISK' if rate < 50 else 'MEDIUM' if rate < 70 else 'LOW RISK'\n",
    "    print(f\"  Cluster {c}: {cluster_counts[c]:,} students, {rate:.1f}% success ‚Üí {risk}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"SUCCESS CRITERIA CHECK\")\n",
    "print(\"-\" * 70)\n",
    "auc_val = roc_auc_score(y_test, y_proba_tuned)\n",
    "acc_val = accuracy_score(y_test, y_pred_tuned)\n",
    "sil_val = silhouette_score(X_cluster_scaled, cluster_labels)\n",
    "\n",
    "print(f\"  {'‚úì' if auc_val > 0.75 else '‚úó'} AUC-ROC > 0.75: {auc_val:.4f}\")\n",
    "print(f\"  {'‚úì' if acc_val > 0.70 else '‚úó'} Accuracy > 70%: {acc_val*100:.1f}%\")\n",
    "print(f\"  {'‚úì' if sil_val > 0.2 else '‚úó'} Silhouette > 0.2: {sil_val:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8Ô∏è‚É£ Phase 6: Deployment Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"                    DEPLOYMENT RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "üìã EARLY WARNING SYSTEM\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "1. Deploy the Random Forest model to predict at-risk students\n",
    "2. Run predictions WEEKLY during the first 4 weeks of term\n",
    "3. Flag students with P(success) < 0.5 for intervention\n",
    "4. Prioritize based on early engagement metrics\n",
    "\n",
    "üìä KEY PREDICTIVE INDICATORS\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Based on feature importance, focus on monitoring:\n",
    "\"\"\")\n",
    "\n",
    "for _, row in importance.head(5).iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['Feature']}\")\n",
    "\n",
    "print(\"\"\"\n",
    "üë• CLUSTER-BASED INTERVENTIONS\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\"\"\")\n",
    "\n",
    "for c in range(OPTIMAL_K):\n",
    "    rate = success_rate[c]\n",
    "    if rate < 50:\n",
    "        print(f\"  Cluster {c} (HIGH RISK - {rate:.0f}%):\")\n",
    "        print(f\"    ‚Üí Immediate personal tutor contact\")\n",
    "        print(f\"    ‚Üí One-on-one study support\")\n",
    "    elif rate < 70:\n",
    "        print(f\"  Cluster {c} (MEDIUM RISK - {rate:.0f}%):\")\n",
    "        print(f\"    ‚Üí Group study skills workshops\")\n",
    "        print(f\"    ‚Üí Peer mentoring programs\")\n",
    "    else:\n",
    "        print(f\"  Cluster {c} (LOW RISK - {rate:.0f}%):\")\n",
    "        print(f\"    ‚Üí Light-touch monitoring\")\n",
    "        print(f\"    ‚Üí Enrichment opportunities\")\n",
    "\n",
    "print(\"\"\"\n",
    "‚ö†Ô∏è LIMITATIONS\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ Model trained on historical data - may not generalize to new courses\n",
    "‚Ä¢ Requires real-time VLE data access for predictions\n",
    "‚Ä¢ Cannot capture external factors (health, family, work)\n",
    "‚Ä¢ Should be validated each semester with new data\n",
    "\n",
    "üîÑ MONITORING PLAN\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "‚Ä¢ Track model accuracy monthly\n",
    "‚Ä¢ Retrain model each academic year\n",
    "‚Ä¢ Collect feedback from tutors on intervention effectiveness\n",
    "‚Ä¢ A/B test interventions to measure impact\n",
    "\n",
    "‚ùì QUESTIONS FOR STAKEHOLDER (AMIR)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "1. What is the acceptable false positive rate for flagging students?\n",
    "2. What resources are available for interventions?\n",
    "3. Are there privacy concerns with predictive monitoring?\n",
    "4. Should the model weight recall over precision?\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìù Summary\n",
    "\n",
    "## CRISP-DM Phases Completed\n",
    "\n",
    "| Phase | Status | Key Activities |\n",
    "|-------|--------|----------------|\n",
    "| 1. Business Understanding | ‚úì | Defined objectives, success criteria |\n",
    "| 2. Data Understanding | ‚úì | EDA, outliers, distributions, correlations, scatter plots |\n",
    "| 3. Data Preparation | ‚úì | Missing values, outlier capping, feature engineering, encoding |\n",
    "| 4. Modelling | ‚úì | 3 classifiers, K-Means clustering, hyperparameter tuning |\n",
    "| 5. Evaluation | ‚úì | Metrics, CV, confusion matrix, cluster analysis |\n",
    "| 6. Deployment | ‚úì | Recommendations, limitations, monitoring plan |\n",
    "\n",
    "## Key Decisions\n",
    "\n",
    "1. **Feature Selection**: Top 15 features by correlation (not 89!)\n",
    "2. **Feature Engineering**: Created ratio, binary, binned, and interaction features\n",
    "3. **Model Choice**: Random Forest (best AUC-ROC)\n",
    "4. **Clustering**: K=4 (based on elbow/silhouette analysis)\n",
    "\n",
    "## Files Generated\n",
    "\n",
    "- This notebook: `FAIDM_CRISP_DM_Analysis.ipynb`\n",
    "- Prerequisite: `oulad_mega_table.csv` (from `Create_Mega_Table.ipynb`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
