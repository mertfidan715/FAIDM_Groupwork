{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIDM Group Project: Complete CRISP-DM Analysis\n",
    "## Student Performance Prediction & Clustering\n",
    "### Open University Learning Analytics Dataset (OULAD)\n",
    "\n",
    "---\n",
    "\n",
    "**Module:** WM9QG-15 Fundamentals of AI and Data Mining\n",
    "\n",
    "**Dataset:** OULAD Mega Table  \n",
    "- **Each row = one student enrolled in one module presentation**\n",
    "- Contains: demographics, VLE engagement, assessment scores, registration info\n",
    "\n",
    "**Tasks:**\n",
    "1. **Classification**: Predict student success (Pass/Distinction) vs failure (Fail/Withdrawn)\n",
    "2. **Clustering**: Segment students by engagement patterns (K-Means & DBSCAN)\n",
    "\n",
    "---\n",
    "\n",
    "# 0ï¸âƒ£ CRISP-DM Overview\n",
    "\n",
    "This notebook follows the **CRISP-DM** (Cross-Industry Standard Process for Data Mining) methodology:\n",
    "\n",
    "| Phase | Description | Sections |\n",
    "|-------|-------------|----------|\n",
    "| 1. Business Understanding | Define objectives and goals | 2ï¸âƒ£ |\n",
    "| 2. Data Understanding | Explore, visualize, identify quality issues | 3ï¸âƒ£ |\n",
    "| 3. Data Preparation | Clean, transform, engineer features | 4ï¸âƒ£ |\n",
    "| 4. Modelling | Build classification and clustering models | 5ï¸âƒ£ 6ï¸âƒ£ |\n",
    "| 5. Evaluation | Assess model performance | 7ï¸âƒ£ |\n",
    "| 6. Deployment | Recommendations for implementation | 8ï¸âƒ£ |\n",
    "\n",
    "**Prerequisite:** Run `Create_Mega_Table.ipynb` first to generate `oulad_mega_table.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1ï¸âƒ£ Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INSTALL REQUIRED PACKAGES (if needed)\n",
    "# =============================================================================\n",
    "\n",
    "# Uncomment the line below if yellowbrick is not installed\n",
    "# !pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, classification_report, confusion_matrix,\n",
    "                             roc_curve, silhouette_score, davies_bouldin_score)\n",
    "\n",
    "# Yellowbrick for clustering visualization (as used in class)\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Scipy for statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"âœ“ All libraries loaded successfully!\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2ï¸âƒ£ Phase 1: Business Understanding\n",
    "\n",
    "## 2.1 Business Context\n",
    "\n",
    "The **Open University (OU)** is the largest university in the UK for undergraduate education, with a focus on distance learning. The university faces challenges with:\n",
    "- **High dropout rates** in online courses\n",
    "- **Late identification** of struggling students\n",
    "- **Limited resources** for personalized intervention\n",
    "\n",
    "## 2.2 Business Objectives\n",
    "\n",
    "1. **Identify at-risk students early** (within first 2-4 weeks) for timely intervention\n",
    "2. **Understand engagement patterns** that differentiate successful vs unsuccessful students\n",
    "3. **Segment students** into groups for targeted support strategies\n",
    "\n",
    "## 2.3 Data Mining Goals\n",
    "\n",
    "| Task | Type | Goal | Success Metric |\n",
    "|------|------|------|----------------|\n",
    "| Task 1 | Classification | Predict Pass/Distinction vs Fail/Withdrawn | AUC-ROC > 0.75, Accuracy > 70% |\n",
    "| Task 2 | Clustering | Segment students into meaningful groups | Silhouette Score > 0.2 |\n",
    "\n",
    "## 2.4 Success Criteria\n",
    "\n",
    "- Model can identify at-risk students with **>75% AUC-ROC**\n",
    "- Early engagement features (first 2 weeks) have **predictive power**\n",
    "- Clusters are **interpretable** and map to distinct outcomes\n",
    "- Recommendations are **actionable** for university staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3ï¸âƒ£ Phase 2: Data Understanding\n",
    "\n",
    "This phase involves thorough exploration of the data to understand its structure, quality, and characteristics.\n",
    "\n",
    "## 3.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD THE MEGA TABLE\n",
    "# =============================================================================\n",
    "# The mega table was created by merging all 7 OULAD tables\n",
    "# Each row represents ONE STUDENT enrolled in ONE MODULE PRESENTATION\n",
    "# =============================================================================\n",
    "\n",
    "# UPDATE THIS PATH if your file is in a different location\n",
    "DATA_PATH = 'oulad_mega_table.csv'\n",
    "\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"âœ“ Data loaded successfully!\")\n",
    "print(f\"\\nðŸ“Š Dataset Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"\\nðŸ“Œ Each row = one student's enrollment in one module\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIRST LOOK AT THE DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(\"-\" * 60)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LIST ALL COLUMNS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"All columns in the mega table:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    print(f\"{i:2}. {col} ({dtype})\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total: {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA TYPES SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Data types summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Separate numerical and categorical\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerical columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MISSING VALUES ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "missing = df.isna().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct,\n",
    "    'Data Type': df.dtypes\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"\\nâš ï¸ {len(missing_df)} columns have missing values\")\n",
    "    print(\"\\nðŸ“ Interpretation:\")\n",
    "    print(\"   - Missing VLE data = students who never accessed the VLE (fill with 0)\")\n",
    "    print(\"   - Missing assessment data = students who didn't submit (fill with 0)\")\n",
    "    print(\"   - Missing imd_band = unknown socioeconomic status (create indicator)\")\n",
    "else:\n",
    "    print(\"âœ“ No missing values found!\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE MISSING VALUES\n",
    "# =============================================================================\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_df['Missing %'].head(15).plot(kind='barh', color='coral')\n",
    "    plt.xlabel('Missing Percentage (%)')\n",
    "    plt.title('Top 15 Columns with Missing Values', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Duplicate Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHECK FOR DUPLICATE ROWS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Duplicate Rows Check:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "n_duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {n_duplicates}\")\n",
    "\n",
    "if n_duplicates > 0:\n",
    "    print(f\"âš ï¸ {n_duplicates} duplicates found ({n_duplicates/len(df)*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"âœ“ No duplicate rows found\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TARGET VARIABLE: final_result\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Target Variable Analysis (final_result):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "target_counts = df['final_result'].value_counts()\n",
    "target_pct = df['final_result'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Distribution:\")\n",
    "for result in target_counts.index:\n",
    "    print(f\"  {result}: {target_counts[result]:,} ({target_pct[result]:.1f}%)\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nðŸ“Š Success (Pass + Distinction): {target_pct.get('Pass', 0) + target_pct.get('Distinction', 0):.1f}%\")\n",
    "print(f\"ðŸ“Š Failure (Fail + Withdrawn): {target_pct.get('Fail', 0) + target_pct.get('Withdrawn', 0):.1f}%\")\n",
    "print(\"\\nâš ï¸ Class imbalance detected - will use stratified sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE TARGET DISTRIBUTION\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = {'Pass': '#2ecc71', 'Distinction': '#3498db', 'Fail': '#e74c3c', 'Withdrawn': '#95a5a6'}\n",
    "order = ['Pass', 'Distinction', 'Fail', 'Withdrawn']\n",
    "color_list = [colors[o] for o in order]\n",
    "\n",
    "target_counts.reindex(order).plot(kind='bar', ax=axes[0], color=color_list, edgecolor='black')\n",
    "axes[0].set_title('Final Results Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Final Result')\n",
    "axes[0].set_ylabel('Number of Students')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "for i, v in enumerate(target_counts.reindex(order)):\n",
    "    axes[0].text(i, v + 200, f'{v:,}', ha='center', fontsize=10)\n",
    "\n",
    "axes[1].pie(target_counts.reindex(order), labels=order, autopct='%1.1f%%', \n",
    "            colors=color_list, startangle=90, explode=[0.02]*4)\n",
    "axes[1].set_title('Final Results Proportion', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Numerical Variables: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY STATISTICS FOR NUMERICAL VARIABLES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Summary Statistics (Numerical Variables):\")\n",
    "print(\"-\" * 60)\n",
    "df.describe().T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Distribution Analysis (Histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DISTRIBUTION OF KEY NUMERICAL VARIABLES\n",
    "# =============================================================================\n",
    "\n",
    "key_vars = ['vle_total_clicks', 'vle_active_days', 'assess_score_mean', \n",
    "            'vle_early_clicks', 'studied_credits', 'num_of_prev_attempts']\n",
    "key_vars = [v for v in key_vars if v in df.columns]\n",
    "\n",
    "print(\"Distribution of Key Variables:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    ax = axes[i]\n",
    "    df[var].hist(bins=50, ax=ax, color='steelblue', edgecolor='black', alpha=0.7, density=True)\n",
    "    df[var].plot(kind='kde', ax=ax, color='red', linewidth=2)\n",
    "    skewness = df[var].skew()\n",
    "    ax.set_title(f'{var}\\n(Skewness: {skewness:.2f})', fontweight='bold')\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel('Density')\n",
    "    if abs(skewness) > 1:\n",
    "        ax.annotate('Highly skewed', xy=(0.7, 0.9), xycoords='axes fraction', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“ Interpretation:\")\n",
    "print(\"   - Skewness > 1: Right-skewed (long tail to the right)\")\n",
    "print(\"   - Skewness < -1: Left-skewed (long tail to the left)\")\n",
    "print(\"   - |Skewness| < 0.5: Approximately symmetric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Skewness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SKEWNESS ANALYSIS FOR ALL NUMERICAL COLUMNS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Skewness Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "skewness = df[numerical_cols].skew().sort_values(ascending=False)\n",
    "\n",
    "print(\"Most positively skewed (right-tailed):\")\n",
    "for var, skew in skewness.head(5).items():\n",
    "    print(f\"  {var}: {skew:.2f}\")\n",
    "\n",
    "print(\"\\nMost negatively skewed (left-tailed):\")\n",
    "for var, skew in skewness.tail(5).items():\n",
    "    print(f\"  {var}: {skew:.2f}\")\n",
    "\n",
    "highly_skewed = (skewness.abs() > 1).sum()\n",
    "print(f\"\\nâš ï¸ {highly_skewed} variables are highly skewed (|skewness| > 1)\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OUTLIER DETECTION USING IQR METHOD\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Outlier Detection (IQR Method):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def count_outliers_iqr(series):\n",
    "    \"\"\"Count outliers using IQR method\"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((series < lower_bound) | (series > upper_bound)).sum()\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "outlier_results = []\n",
    "for col in key_vars:\n",
    "    n_outliers, lb, ub = count_outliers_iqr(df[col].dropna())\n",
    "    pct = n_outliers / len(df) * 100\n",
    "    outlier_results.append({\n",
    "        'Variable': col,\n",
    "        'Outliers': n_outliers,\n",
    "        'Percentage': f'{pct:.1f}%',\n",
    "        'Lower Bound': f'{lb:.1f}',\n",
    "        'Upper Bound': f'{ub:.1f}'\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_results)\n",
    "print(outlier_df.to_string(index=False))\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE OUTLIERS WITH BOX PLOTS\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    ax = axes[i]\n",
    "    df.boxplot(column=var, ax=ax)\n",
    "    ax.set_title(f'{var}', fontweight='bold')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "plt.suptitle('Box Plots Showing Outliers', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Categorical Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATEGORICAL VARIABLES DISTRIBUTION\n",
    "# =============================================================================\n",
    "\n",
    "cat_vars = ['gender', 'age_band', 'highest_education', 'imd_band', 'disability', 'region']\n",
    "cat_vars = [v for v in cat_vars if v in df.columns]\n",
    "\n",
    "print(\"Categorical Variables Distribution:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for var in cat_vars:\n",
    "    print(f\"\\n{var}:\")\n",
    "    print(df[var].value_counts())\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE CATEGORICAL VARIABLES\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(cat_vars[:6]):\n",
    "    ax = axes[i]\n",
    "    df[var].value_counts().plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "    ax.set_title(f'{var} Distribution', fontweight='bold')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 Feature Relationships with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NUMERICAL FEATURES VS TARGET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Feature Distributions by Outcome:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    ax = axes[i]\n",
    "    df.boxplot(column=var, by='final_result', ax=ax, positions=[1, 2, 3, 4])\n",
    "    ax.set_title(f'{var} by Outcome', fontweight='bold')\n",
    "    ax.set_xlabel('Final Result')\n",
    "    ax.set_ylabel(var)\n",
    "    plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“ Observation: Students who Pass/Distinction tend to have higher VLE engagement and assessment scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATEGORICAL FEATURES VS TARGET\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(cat_vars[:6]):\n",
    "    ax = axes[i]\n",
    "    ct = pd.crosstab(df[var], df['final_result'], normalize='index') * 100\n",
    "    order = [c for c in ['Pass', 'Distinction', 'Fail', 'Withdrawn'] if c in ct.columns]\n",
    "    ct[order].plot(kind='bar', stacked=True, ax=ax,\n",
    "                   color=['#2ecc71', '#3498db', '#e74c3c', '#95a5a6'])\n",
    "    ax.set_title(f'Outcome by {var}', fontweight='bold')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 Scatter Plots (Feature Relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SCATTER PLOTS BETWEEN KEY FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Scatter Plots Between Key Features:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df['target_binary'] = df['final_result'].apply(lambda x: 1 if x in ['Pass', 'Distinction'] else 0)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "scatter = ax.scatter(df['vle_active_days'], df['vle_total_clicks'], \n",
    "                     c=df['target_binary'], cmap='RdYlGn', alpha=0.3, s=10)\n",
    "ax.set_xlabel('VLE Active Days')\n",
    "ax.set_ylabel('VLE Total Clicks')\n",
    "ax.set_title('Total Clicks vs Active Days', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Success (1=Pass/Dist)')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "scatter = ax.scatter(df['vle_total_clicks'], df['assess_score_mean'], \n",
    "                     c=df['target_binary'], cmap='RdYlGn', alpha=0.3, s=10)\n",
    "ax.set_xlabel('VLE Total Clicks')\n",
    "ax.set_ylabel('Assessment Score Mean')\n",
    "ax.set_title('Assessment Score vs Total Clicks', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Success (1=Pass/Dist)')\n",
    "\n",
    "if 'vle_early_clicks' in df.columns:\n",
    "    ax = axes[1, 0]\n",
    "    scatter = ax.scatter(df['vle_early_clicks'], df['vle_total_clicks'], \n",
    "                         c=df['target_binary'], cmap='RdYlGn', alpha=0.3, s=10)\n",
    "    ax.set_xlabel('VLE Early Clicks (First 2 Weeks)')\n",
    "    ax.set_ylabel('VLE Total Clicks')\n",
    "    ax.set_title('Early Engagement vs Total Engagement', fontweight='bold')\n",
    "    plt.colorbar(scatter, ax=ax, label='Success (1=Pass/Dist)')\n",
    "\n",
    "ax = axes[1, 1]\n",
    "scatter = ax.scatter(df['vle_active_days'], df['assess_score_mean'], \n",
    "                     c=df['target_binary'], cmap='RdYlGn', alpha=0.3, s=10)\n",
    "ax.set_xlabel('VLE Active Days')\n",
    "ax.set_ylabel('Assessment Score Mean')\n",
    "ax.set_title('Assessment Score vs Active Days', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Success (1=Pass/Dist)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“ Observations:\")\n",
    "print(\"   - Green points (success) cluster in high-engagement regions\")\n",
    "print(\"   - Red points (failure) cluster in low-engagement regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CORRELATION MATRIX\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Correlation Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "corr_cols = key_vars + ['target_binary']\n",
    "corr_cols = [c for c in corr_cols if c in df.columns]\n",
    "\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix (Key Variables)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CORRELATION WITH TARGET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Correlation with Target (Success):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "all_numerical = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "all_numerical = [c for c in all_numerical if c != 'target_binary' and c != 'id_student']\n",
    "\n",
    "target_corr = df[all_numerical + ['target_binary']].corr()['target_binary'].drop('target_binary')\n",
    "target_corr_sorted = target_corr.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 15 features correlated with success:\")\n",
    "for i, (feat, corr) in enumerate(target_corr_sorted.head(15).items(), 1):\n",
    "    direction = '+' if target_corr[feat] > 0 else '-'\n",
    "    print(f\"  {i:2}. {feat}: {direction}{corr:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 Data Understanding Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA UNDERSTANDING SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"                    DATA UNDERSTANDING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸ“Š DATASET OVERVIEW\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Rows: {df.shape[0]:,} (student-module enrollments)\n",
    "â€¢ Columns: {df.shape[1]}\n",
    "â€¢ Numerical features: {len(numerical_cols)}\n",
    "â€¢ Categorical features: {len(categorical_cols)}\n",
    "\n",
    "ðŸŽ¯ TARGET VARIABLE (final_result)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Pass: {target_pct.get('Pass', 0):.1f}%\n",
    "â€¢ Distinction: {target_pct.get('Distinction', 0):.1f}%\n",
    "â€¢ Fail: {target_pct.get('Fail', 0):.1f}%\n",
    "â€¢ Withdrawn: {target_pct.get('Withdrawn', 0):.1f}%\n",
    "\n",
    "ðŸ“ˆ KEY FINDINGS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ VLE engagement strongly correlates with success\n",
    "â€¢ Assessment scores strongly correlate with success\n",
    "â€¢ Early engagement shows predictive potential\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4ï¸âƒ£ Phase 3: Data Preparation\n",
    "\n",
    "## 4.1 Create Working Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE WORKING COPY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 1: Create working copy\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df_prep = df.copy()\n",
    "print(f\"âœ“ Created copy: {df_prep.shape[0]:,} rows Ã— {df_prep.shape[1]} columns\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HANDLE MISSING VALUES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 2: Handle missing values\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create missing indicator for imd_band\n",
    "if 'imd_band' in df_prep.columns:\n",
    "    df_prep['imd_band_missing'] = df_prep['imd_band'].isna().astype(int)\n",
    "    df_prep['imd_band'] = df_prep['imd_band'].fillna('Unknown')\n",
    "    print(\"âœ“ imd_band: Created missing indicator, filled with 'Unknown'\")\n",
    "\n",
    "# Fill VLE columns with 0\n",
    "vle_cols = [c for c in df_prep.columns if c.startswith('vle_')]\n",
    "df_prep[vle_cols] = df_prep[vle_cols].fillna(0)\n",
    "print(f\"âœ“ VLE columns ({len(vle_cols)}): Filled with 0\")\n",
    "\n",
    "# Fill assessment columns with 0\n",
    "assess_cols = [c for c in df_prep.columns if c.startswith('assess_')]\n",
    "df_prep[assess_cols] = df_prep[assess_cols].fillna(0)\n",
    "print(f\"âœ“ Assessment columns ({len(assess_cols)}): Filled with 0\")\n",
    "\n",
    "# Impute remaining numerical with median\n",
    "num_cols_remaining = df_prep.select_dtypes(include=[np.number]).columns\n",
    "cols_with_na = [c for c in num_cols_remaining if df_prep[c].isna().any()]\n",
    "\n",
    "if cols_with_na:\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df_prep[cols_with_na] = imputer.fit_transform(df_prep[cols_with_na])\n",
    "    print(f\"âœ“ Remaining numerical ({len(cols_with_na)}): Imputed with median\")\n",
    "\n",
    "print(f\"\\nâœ“ Remaining missing values: {df_prep.isna().sum().sum()}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HANDLE OUTLIERS (CAPPING)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 3: Handle outliers (capping at 99th percentile)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cols_to_cap = ['vle_total_clicks', 'vle_active_days', 'vle_early_clicks', 'vle_unique_resources']\n",
    "cols_to_cap = [c for c in cols_to_cap if c in df_prep.columns]\n",
    "\n",
    "for col in cols_to_cap:\n",
    "    p99 = df_prep[col].quantile(0.99)\n",
    "    n_capped = (df_prep[col] > p99).sum()\n",
    "    df_prep[col] = df_prep[col].clip(upper=p99)\n",
    "    print(f\"âœ“ {col}: Capped {n_capped} values at {p99:.0f}\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Feature Engineering - Ratio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING: RATIO FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 4: Feature Engineering - Ratio Features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Clicks per active day\n",
    "df_prep['clicks_per_day'] = df_prep['vle_total_clicks'] / df_prep['vle_active_days'].replace(0, 1)\n",
    "print(\"âœ“ Created: clicks_per_day\")\n",
    "\n",
    "# Early engagement ratio\n",
    "if 'vle_early_clicks' in df_prep.columns:\n",
    "    df_prep['early_engagement_ratio'] = df_prep['vle_early_clicks'] / df_prep['vle_total_clicks'].replace(0, 1)\n",
    "    print(\"âœ“ Created: early_engagement_ratio\")\n",
    "\n",
    "# Resources per active day\n",
    "if 'vle_unique_resources' in df_prep.columns:\n",
    "    df_prep['resources_per_day'] = df_prep['vle_unique_resources'] / df_prep['vle_active_days'].replace(0, 1)\n",
    "    print(\"âœ“ Created: resources_per_day\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Feature Engineering - Binary Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING: BINARY FLAGS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 5: Feature Engineering - Binary Flags\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if 'vle_early_clicks' in df_prep.columns:\n",
    "    df_prep['is_active_early'] = (df_prep['vle_early_clicks'] > 0).astype(int)\n",
    "    print(\"âœ“ Created: is_active_early\")\n",
    "\n",
    "if 'date_registration' in df_prep.columns:\n",
    "    df_prep['registered_early'] = (df_prep['date_registration'] < 0).astype(int)\n",
    "    print(\"âœ“ Created: registered_early\")\n",
    "\n",
    "if 'assess_count' in df_prep.columns:\n",
    "    df_prep['has_submitted'] = (df_prep['assess_count'] > 0).astype(int)\n",
    "    print(\"âœ“ Created: has_submitted\")\n",
    "\n",
    "if 'assess_score_mean' in df_prep.columns:\n",
    "    df_prep['is_high_performer'] = (df_prep['assess_score_mean'] >= 70).astype(int)\n",
    "    print(\"âœ“ Created: is_high_performer\")\n",
    "\n",
    "if 'num_of_prev_attempts' in df_prep.columns:\n",
    "    df_prep['has_prev_attempts'] = (df_prep['num_of_prev_attempts'] > 0).astype(int)\n",
    "    print(\"âœ“ Created: has_prev_attempts\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Feature Engineering - Binning with pd.cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING: BINNING WITH pd.cut()\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 6: Feature Engineering - Binning with pd.cut()\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Engagement level bins\n",
    "df_prep['engagement_level'] = pd.cut(\n",
    "    df_prep['vle_total_clicks'],\n",
    "    bins=[0, 100, 500, 1000, 2000, float('inf')],\n",
    "    labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'],\n",
    "    include_lowest=True\n",
    ")\n",
    "print(\"âœ“ Created: engagement_level\")\n",
    "print(f\"   Distribution: {df_prep['engagement_level'].value_counts().to_dict()}\")\n",
    "\n",
    "# Score level bins\n",
    "df_prep['score_level'] = pd.cut(\n",
    "    df_prep['assess_score_mean'],\n",
    "    bins=[0, 40, 60, 70, 80, 100],\n",
    "    labels=['Failing', 'Poor', 'Average', 'Good', 'Excellent'],\n",
    "    include_lowest=True\n",
    ")\n",
    "print(\"\\nâœ“ Created: score_level\")\n",
    "print(f\"   Distribution: {df_prep['score_level'].value_counts().to_dict()}\")\n",
    "\n",
    "# Activity level bins\n",
    "df_prep['activity_level'] = pd.cut(\n",
    "    df_prep['vle_active_days'],\n",
    "    bins=[0, 10, 30, 60, 100, float('inf')],\n",
    "    labels=['Minimal', 'Low', 'Moderate', 'Regular', 'Intensive'],\n",
    "    include_lowest=True\n",
    ")\n",
    "print(\"\\nâœ“ Created: activity_level\")\n",
    "print(f\"   Distribution: {df_prep['activity_level'].value_counts().to_dict()}\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE BINNED FEATURES VS OUTCOME\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "binned_features = ['engagement_level', 'score_level', 'activity_level']\n",
    "\n",
    "for i, feat in enumerate(binned_features):\n",
    "    ax = axes[i]\n",
    "    ct = pd.crosstab(df_prep[feat], df_prep['final_result'], normalize='index') * 100\n",
    "    order = [c for c in ['Pass', 'Distinction', 'Fail', 'Withdrawn'] if c in ct.columns]\n",
    "    ct[order].plot(kind='bar', stacked=True, ax=ax,\n",
    "                   color=['#2ecc71', '#3498db', '#e74c3c', '#95a5a6'])\n",
    "    ax.set_title(f'Outcome by {feat}', fontweight='bold')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Feature Engineering - Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING: INTERACTION FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 7: Feature Engineering - Interaction Features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df_prep['engagement_score_product'] = df_prep['vle_total_clicks'] * df_prep['assess_score_mean'] / 1000\n",
    "print(\"âœ“ Created: engagement_score_product\")\n",
    "\n",
    "df_prep['consistency_score'] = df_prep['vle_active_days'] * df_prep['assess_score_mean'] / 100\n",
    "print(\"âœ“ Created: consistency_score\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENCODE CATEGORICAL VARIABLES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 8: Encode categorical variables\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# One-hot encoding for nominal variables\n",
    "nominal_cols = ['gender', 'disability']\n",
    "for col in nominal_cols:\n",
    "    if col in df_prep.columns:\n",
    "        dummies = pd.get_dummies(df_prep[col], prefix=col, drop_first=True)\n",
    "        df_prep = pd.concat([df_prep, dummies], axis=1)\n",
    "        print(f\"âœ“ One-hot encoded: {col}\")\n",
    "\n",
    "# Ordinal encoding for education\n",
    "education_order = {\n",
    "    'No Formal quals': 0, 'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2, 'HE Qualification': 3,\n",
    "    'Post Graduate Qualification': 4\n",
    "}\n",
    "if 'highest_education' in df_prep.columns:\n",
    "    df_prep['education_level'] = df_prep['highest_education'].map(education_order)\n",
    "    print(f\"âœ“ Ordinal encoded: highest_education\")\n",
    "\n",
    "# Ordinal encoding for age band\n",
    "age_order = {'0-35': 0, '35-55': 1, '55<=': 2}\n",
    "if 'age_band' in df_prep.columns:\n",
    "    df_prep['age_level'] = df_prep['age_band'].map(age_order)\n",
    "    print(f\"âœ“ Ordinal encoded: age_band\")\n",
    "\n",
    "# Ordinal encoding for binned features\n",
    "engagement_order = {'Very Low': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very High': 4}\n",
    "df_prep['engagement_level_encoded'] = df_prep['engagement_level'].map(engagement_order)\n",
    "\n",
    "score_order = {'Failing': 0, 'Poor': 1, 'Average': 2, 'Good': 3, 'Excellent': 4}\n",
    "df_prep['score_level_encoded'] = df_prep['score_level'].map(score_order)\n",
    "\n",
    "activity_order = {'Minimal': 0, 'Low': 1, 'Moderate': 2, 'Regular': 3, 'Intensive': 4}\n",
    "df_prep['activity_level_encoded'] = df_prep['activity_level'].map(activity_order)\n",
    "print(f\"âœ“ Ordinal encoded: binned features\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Create Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE BINARY TARGET VARIABLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 9: Create target variable\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df_prep['target'] = df_prep['final_result'].apply(\n",
    "    lambda x: 1 if x in ['Pass', 'Distinction'] else 0\n",
    ")\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(df_prep['target'].value_counts())\n",
    "print(f\"\\nSuccess rate: {df_prep['target'].mean()*100:.1f}%\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IDENTIFY CANDIDATE FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 10: Identify candidate features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "exclude_cols = [\n",
    "    'id_student', 'student_module_key', 'code_module', 'code_presentation',\n",
    "    'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability',\n",
    "    'final_result', 'target', 'target_binary',\n",
    "    'date_registration', 'date_unregistration',\n",
    "    'engagement_level', 'score_level', 'activity_level'\n",
    "]\n",
    "\n",
    "candidate_features = [col for col in df_prep.columns \n",
    "                      if col not in exclude_cols \n",
    "                      and df_prep[col].dtype in ['int64', 'float64', 'int32', 'float32', 'uint8', 'bool']]\n",
    "\n",
    "print(f\"Total candidate features: {len(candidate_features)}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECT TOP K FEATURES BY CORRELATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 11: Select top K features by correlation\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "correlations = df_prep[candidate_features + ['target']].corr()['target'].drop('target')\n",
    "correlations_abs = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 features by |correlation| with target:\")\n",
    "for i, (feat, corr) in enumerate(correlations_abs.head(20).items(), 1):\n",
    "    direction = '+' if correlations[feat] > 0 else '-'\n",
    "    print(f\"  {i:2}. {feat}: {direction}{corr:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECT FINAL FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "K = 15  # Number of features to use\n",
    "\n",
    "selected_features = correlations_abs.head(K).index.tolist()\n",
    "\n",
    "print(f\"\\nâœ“ SELECTED TOP {K} FEATURES FOR MODELLING:\")\n",
    "print(\"=\" * 60)\n",
    "for i, feat in enumerate(selected_features, 1):\n",
    "    corr = correlations[feat]\n",
    "    print(f\"  {i:2}. {feat} (r = {corr:+.4f})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df_prep[selected_features + ['target']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f', square=True)\n",
    "plt.title(f'Correlation Matrix (Selected {K} Features + Target)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE FINAL FEATURE MATRIX AND TARGET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 12: Create final dataset\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "X = df_prep[selected_features].copy()\n",
    "y = df_prep['target'].copy()\n",
    "\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "print(f\"Feature matrix X: {X.shape[0]:,} rows Ã— {X.shape[1]} features\")\n",
    "print(f\"Target vector y: {y.shape[0]:,} values\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5ï¸âƒ£ Phase 4: Modelling - Task 1 (Classification)\n",
    "\n",
    "## 5.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 13: Train-test split (stratified)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE SCALING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 14: Feature scaling (StandardScaler)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ“ Features scaled (mean=0, std=1)\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAIN AND EVALUATE MULTIPLE MODELS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 15: Train and evaluate models\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸ”„ Training {name}...\")\n",
    "    \n",
    "    if 'Logistic' in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "    \n",
    "    print(f\"   âœ“ Accuracy: {results[name]['Accuracy']:.4f}\")\n",
    "    print(f\"   âœ“ AUC-ROC:  {results[name]['AUC-ROC']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPARE MODEL PERFORMANCE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 16: Model comparison\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df.round(4))\n",
    "\n",
    "best_model_name = results_df['AUC-ROC'].idxmax()\n",
    "print(f\"\\nðŸ† Best model (by AUC-ROC): {best_model_name}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "results_df.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xticklabels(results_df.index, rotation=0)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DETAILED ANALYSIS OF BEST MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 17: Detailed analysis - Random Forest\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rf = models['Random Forest']\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, \n",
    "                            target_names=['Fail/Withdrawn', 'Pass/Distinction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Fail/Withdrawn', 'Pass/Distinction'],\n",
    "            yticklabels=['Fail/Withdrawn', 'Pass/Distinction'])\n",
    "plt.title('Confusion Matrix - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 18: Feature importance\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature importance ranking:\")\n",
    "for i, row in importance.iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Importance']:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(importance)), importance['Importance'], color='steelblue')\n",
    "plt.yticks(range(len(importance)), importance['Feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ROC CURVES COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 19: ROC curves\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "for (name, model), color in zip(models.items(), colors):\n",
    "    if 'Logistic' in name:\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})', color=color, linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.500)')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HYPERPARAMETER TUNING WITH GRIDSEARCHCV\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 20: Hyperparameter tuning (GridSearchCV)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "print(\"ðŸ”„ Running GridSearchCV...\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nâœ“ Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"âœ“ Best CV AUC-ROC: {grid_search.best_score_:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned model\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_tuned = best_rf.predict(X_test)\n",
    "y_proba_tuned = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Tuned model performance on test set:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"AUC-ROC:   {roc_auc_score(y_test, y_proba_tuned):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CROSS-VALIDATION FOR ROBUST EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 21: 5-Fold Cross-Validation\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f\"CV AUC-ROC scores: {cv_scores.round(4)}\")\n",
    "print(f\"Mean: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6ï¸âƒ£ Phase 4: Modelling - Task 2 (Clustering)\n",
    "\n",
    "This section compares two clustering algorithms:\n",
    "1. **K-Means** - Partitional clustering (requires k to be specified)\n",
    "2. **DBSCAN** - Density-based clustering (automatically finds k)\n",
    "\n",
    "## 6.1 Select Clustering Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECT FEATURES FOR CLUSTERING\n",
    "# =============================================================================\n",
    "# Using engagement-focused features to segment students by behavior\n",
    "# As taught in class, we select a subset of numeric variables for clustering\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 22: Select clustering features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cluster_features = [\n",
    "    'vle_total_clicks', 'vle_active_days', 'vle_unique_resources',\n",
    "    'assess_score_mean', 'assess_count', 'clicks_per_day'\n",
    "]\n",
    "cluster_features = [f for f in cluster_features if f in df_prep.columns]\n",
    "\n",
    "print(f\"Using {len(cluster_features)} features for clustering:\")\n",
    "for f in cluster_features:\n",
    "    print(f\"  - {f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and scale clustering data\n",
    "X_cluster = df_prep[cluster_features].fillna(0)\n",
    "X_cluster = X_cluster.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Scale data (important for both K-Means and DBSCAN)\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "print(f\"Clustering data: {X_cluster_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6.2 K-Means Clustering\n",
    "\n",
    "### 6.2.1 Find Optimal K using Yellowbrick KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIND OPTIMAL K USING YELLOWBRICK (as taught in class)\n",
    "# =============================================================================\n",
    "# KElbowVisualizer automatically finds the \"elbow\" in the inertia curve\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 23: Find optimal k using KElbowVisualizer (Yellowbrick)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create K-Means model with k-means++ initialization (as in class)\n",
    "model = KMeans(init='k-means++', random_state=42)\n",
    "\n",
    "# Use KElbowVisualizer to find optimal k\n",
    "visualizer = KElbowVisualizer(model, k=(2, 10))\n",
    "visualizer.fit(X_cluster_scaled)\n",
    "visualizer.show()\n",
    "plt.show()\n",
    "\n",
    "# Get the optimal k\n",
    "optimal_k_elbow = visualizer.elbow_value_\n",
    "print(f\"\\nâœ“ Optimal k (from elbow): {optimal_k_elbow}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Evaluate K with Multiple Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUATE K VALUES WITH SILHOUETTE AND DAVIES-BOULDIN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 24: Evaluate k values with multiple metrics\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "K_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "db_scores = []\n",
    "\n",
    "for k in K_range:\n",
    "    # Use k-means++ initialization (as taught in class)\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_cluster_scaled, labels))\n",
    "    db_scores.append(davies_bouldin_score(X_cluster_scaled, labels))\n",
    "    print(f\"k={k}: Silhouette={silhouettes[-1]:.4f}, Davies-Bouldin={db_scores[-1]:.4f}\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all metrics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2)\n",
    "axes[0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(K_range, silhouettes, 'go-', linewidth=2)\n",
    "axes[1].set_xlabel('Number of Clusters (k)')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette (higher = better)', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(K_range, db_scores, 'ro-', linewidth=2)\n",
    "axes[2].set_xlabel('Number of Clusters (k)')\n",
    "axes[2].set_ylabel('Davies-Bouldin Index')\n",
    "axes[2].set_title('Davies-Bouldin (lower = better)', fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Fit Final K-Means Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIT FINAL K-MEANS MODEL\n",
    "# =============================================================================\n",
    "# Using k-means++ initialization as taught in class\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 25: Fit K-Means with optimal k\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Use the elbow value or choose based on analysis\n",
    "OPTIMAL_K = optimal_k_elbow if optimal_k_elbow else 4\n",
    "\n",
    "# Fit K-Means with k-means++ initialization\n",
    "kmeans_final = KMeans(\n",
    "    n_clusters=OPTIMAL_K, \n",
    "    init='k-means++',  # As taught in class\n",
    "    random_state=42, \n",
    "    n_init=10\n",
    ")\n",
    "kmeans_labels = kmeans_final.fit_predict(X_cluster_scaled)\n",
    "\n",
    "df_prep['kmeans_cluster'] = kmeans_labels\n",
    "\n",
    "print(f\"K-Means with k={OPTIMAL_K} (init='k-means++'):\")\n",
    "kmeans_counts = pd.Series(kmeans_labels).value_counts().sort_index()\n",
    "for c, count in kmeans_counts.items():\n",
    "    pct = count / len(kmeans_labels) * 100\n",
    "    print(f\"  Cluster {c}: {count:,} students ({pct:.1f}%)\")\n",
    "\n",
    "kmeans_silhouette = silhouette_score(X_cluster_scaled, kmeans_labels)\n",
    "kmeans_db = davies_bouldin_score(X_cluster_scaled, kmeans_labels)\n",
    "print(f\"\\nSilhouette Score: {kmeans_silhouette:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {kmeans_db:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 K-Means Cluster Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# K-MEANS CLUSTER PROFILING\n",
    "# =============================================================================\n",
    "# Calculate the average values for every cluster (as taught in class)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 26: K-Means cluster profiling\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Calculate average values for each cluster (as taught in class)\n",
    "kmeans_profiles = df_prep.groupby('kmeans_cluster')[cluster_features].mean()\n",
    "print(\"Average values for each K-Means cluster:\")\n",
    "print(kmeans_profiles.round(2).T)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BOXPLOTS FOR EACH FEATURE BY CLUSTER (as taught in class)\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(cluster_features[:6]):\n",
    "    ax = axes[i]\n",
    "    sns.boxplot(x='kmeans_cluster', y=feat, data=df_prep, ax=ax)\n",
    "    ax.set_title(f'Boxplot of {feat} by K-Means Cluster', fontweight='bold')\n",
    "    ax.set_xlabel('Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 K-Means Clusters vs Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# K-MEANS CLUSTER VS OUTCOME ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 27: K-Means cluster vs outcome\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "crosstab_km = pd.crosstab(df_prep['kmeans_cluster'], df_prep['final_result'], normalize='index') * 100\n",
    "print(\"Outcome distribution by K-Means cluster (%):\")\n",
    "print(crosstab_km.round(1))\n",
    "\n",
    "success_rate_km = df_prep.groupby('kmeans_cluster')['target'].mean() * 100\n",
    "print(\"\\nSuccess rate by K-Means cluster:\")\n",
    "for c, rate in success_rate_km.items():\n",
    "    risk = 'HIGH RISK' if rate < 50 else 'MEDIUM RISK' if rate < 70 else 'LOW RISK'\n",
    "    print(f\"  Cluster {c}: {rate:.1f}% - {risk}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6.3 DBSCAN Clustering\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a density-based clustering algorithm that:\n",
    "- Does NOT require specifying k beforehand\n",
    "- Can find arbitrarily shaped clusters\n",
    "- Identifies noise points (outliers)\n",
    "\n",
    "### 6.3.1 DBSCAN Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DBSCAN PARAMETER SELECTION\n",
    "# =============================================================================\n",
    "# DBSCAN has two main parameters:\n",
    "# - eps: Maximum distance between two samples to be considered neighbors\n",
    "# - min_samples: Minimum number of samples in a neighborhood to form a cluster\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 28: DBSCAN parameter selection\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Test different eps values\n",
    "eps_values = [0.3, 0.5, 0.7, 1.0, 1.5, 2.0]\n",
    "min_samples_values = [5, 10, 15]\n",
    "\n",
    "dbscan_results = []\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samp in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samp)\n",
    "        labels = dbscan.fit_predict(X_cluster_scaled)\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = (labels == -1).sum()\n",
    "        noise_pct = n_noise / len(labels) * 100\n",
    "        \n",
    "        # Calculate silhouette only if more than 1 cluster and not all noise\n",
    "        if n_clusters > 1 and n_noise < len(labels) * 0.9:\n",
    "            # Exclude noise points for silhouette calculation\n",
    "            mask = labels != -1\n",
    "            if len(set(labels[mask])) > 1:\n",
    "                sil = silhouette_score(X_cluster_scaled[mask], labels[mask])\n",
    "            else:\n",
    "                sil = -1\n",
    "        else:\n",
    "            sil = -1\n",
    "        \n",
    "        dbscan_results.append({\n",
    "            'eps': eps, 'min_samples': min_samp,\n",
    "            'n_clusters': n_clusters, 'noise_pct': noise_pct, 'silhouette': sil\n",
    "        })\n",
    "\n",
    "dbscan_df = pd.DataFrame(dbscan_results)\n",
    "print(\"DBSCAN parameter search results:\")\n",
    "print(dbscan_df.to_string(index=False))\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Fit Final DBSCAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIT FINAL DBSCAN MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 29: Fit DBSCAN\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Choose parameters based on above analysis (balance clusters vs noise)\n",
    "best_params = dbscan_df[dbscan_df['silhouette'] > 0].sort_values('silhouette', ascending=False)\n",
    "if len(best_params) > 0:\n",
    "    EPS = best_params.iloc[0]['eps']\n",
    "    MIN_SAMPLES = int(best_params.iloc[0]['min_samples'])\n",
    "else:\n",
    "    EPS = 1.0\n",
    "    MIN_SAMPLES = 10\n",
    "\n",
    "print(f\"Selected parameters: eps={EPS}, min_samples={MIN_SAMPLES}\")\n",
    "\n",
    "dbscan_final = DBSCAN(eps=EPS, min_samples=MIN_SAMPLES)\n",
    "dbscan_labels = dbscan_final.fit_predict(X_cluster_scaled)\n",
    "\n",
    "df_prep['dbscan_cluster'] = dbscan_labels\n",
    "\n",
    "n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = (dbscan_labels == -1).sum()\n",
    "\n",
    "print(f\"\\nDBSCAN Results:\")\n",
    "print(f\"  Number of clusters: {n_clusters_dbscan}\")\n",
    "print(f\"  Noise points: {n_noise} ({n_noise/len(dbscan_labels)*100:.1f}%)\")\n",
    "\n",
    "dbscan_counts = pd.Series(dbscan_labels).value_counts().sort_index()\n",
    "print(f\"\\nCluster distribution:\")\n",
    "for c, count in dbscan_counts.items():\n",
    "    label = 'Noise' if c == -1 else f'Cluster {c}'\n",
    "    pct = count / len(dbscan_labels) * 100\n",
    "    print(f\"  {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Silhouette (excluding noise)\n",
    "mask = dbscan_labels != -1\n",
    "if len(set(dbscan_labels[mask])) > 1:\n",
    "    dbscan_silhouette = silhouette_score(X_cluster_scaled[mask], dbscan_labels[mask])\n",
    "    print(f\"\\nSilhouette Score (excl. noise): {dbscan_silhouette:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 DBSCAN Cluster Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DBSCAN CLUSTER PROFILING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 30: DBSCAN cluster profiling\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "dbscan_profiles = df_prep.groupby('dbscan_cluster')[cluster_features].mean()\n",
    "print(\"Average values for each DBSCAN cluster:\")\n",
    "print(dbscan_profiles.round(2).T)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for DBSCAN clusters\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(cluster_features[:6]):\n",
    "    ax = axes[i]\n",
    "    sns.boxplot(x='dbscan_cluster', y=feat, data=df_prep, ax=ax)\n",
    "    ax.set_title(f'Boxplot of {feat} by DBSCAN Cluster', fontweight='bold')\n",
    "    ax.set_xlabel('Cluster (-1 = Noise)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4 DBSCAN Clusters vs Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DBSCAN CLUSTER VS OUTCOME ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 31: DBSCAN cluster vs outcome\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "crosstab_db = pd.crosstab(df_prep['dbscan_cluster'], df_prep['final_result'], normalize='index') * 100\n",
    "print(\"Outcome distribution by DBSCAN cluster (%):\")\n",
    "print(crosstab_db.round(1))\n",
    "\n",
    "success_rate_db = df_prep.groupby('dbscan_cluster')['target'].mean() * 100\n",
    "print(\"\\nSuccess rate by DBSCAN cluster:\")\n",
    "for c, rate in success_rate_db.items():\n",
    "    label = 'Noise' if c == -1 else f'Cluster {c}'\n",
    "    risk = 'HIGH RISK' if rate < 50 else 'MEDIUM RISK' if rate < 70 else 'LOW RISK'\n",
    "    print(f\"  {label}: {rate:.1f}% - {risk}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6.4 Comparison: K-Means vs DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPARISON AND DISCUSSION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 32: K-Means vs DBSCAN comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Aspect             â”‚ K-Means             â”‚ DBSCAN              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\"\"\")\n",
    "print(f\"â”‚ Clusters found     â”‚ {OPTIMAL_K:<19} â”‚ {n_clusters_dbscan:<19} â”‚\")\n",
    "print(f\"â”‚ Silhouette Score   â”‚ {kmeans_silhouette:<19.4f} â”‚ {dbscan_silhouette if 'dbscan_silhouette' in dir() else 'N/A':<19} â”‚\")\n",
    "print(f\"â”‚ Noise points       â”‚ {'0':<19} â”‚ {n_noise:<19} â”‚\")\n",
    "print(f\"â”‚ Requires k         â”‚ {'Yes':<19} â”‚ {'No':<19} â”‚\")\n",
    "print(f\"â”‚ Handles outliers   â”‚ {'No':<19} â”‚ {'Yes':<19} â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ“ DISCUSSION:\n",
    "\n",
    "K-Means:\n",
    "  âœ“ Simple and fast\n",
    "  âœ“ Works well with spherical clusters\n",
    "  âœ— Requires specifying k beforehand\n",
    "  âœ— Sensitive to outliers\n",
    "\n",
    "DBSCAN:\n",
    "  âœ“ Automatically finds number of clusters\n",
    "  âœ“ Identifies noise/outliers\n",
    "  âœ“ Can find non-spherical clusters\n",
    "  âœ— Requires tuning eps and min_samples\n",
    "  âœ— Struggles with varying density\n",
    "\n",
    "For this dataset, K-Means is recommended because:\n",
    "  â€¢ Student engagement data forms relatively spherical clusters\n",
    "  â€¢ We want to assign ALL students to a group (no noise)\n",
    "  â€¢ Interpretability is important for interventions\n",
    "\"\"\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PCA VISUALIZATION OF BOTH CLUSTERING METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 33: PCA visualization\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "print(f\"Variance explained: PC1={pca.explained_variance_ratio_[0]:.1%}, PC2={pca.explained_variance_ratio_[1]:.1%}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# K-Means clusters\n",
    "ax = axes[0]\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.5, s=10)\n",
    "centers_pca = pca.transform(kmeans_final.cluster_centers_)\n",
    "ax.scatter(centers_pca[:, 0], centers_pca[:, 1], c='red', marker='X', s=300, edgecolors='black', linewidths=2)\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "ax.set_title('K-Means Clusters (PCA)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "# DBSCAN clusters\n",
    "ax = axes[1]\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_labels, cmap='viridis', alpha=0.5, s=10)\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "ax.set_title('DBSCAN Clusters (PCA)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster (-1=Noise)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Final Cluster Visualization (K-Means vs Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL K-MEANS VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked outcomes by K-Means cluster\n",
    "order = ['Pass', 'Distinction', 'Fail', 'Withdrawn']\n",
    "cols = [c for c in order if c in crosstab_km.columns]\n",
    "crosstab_km[cols].plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                       color=['#2ecc71', '#3498db', '#e74c3c', '#95a5a6'])\n",
    "axes[0].set_title('Outcomes by K-Means Cluster', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Percentage')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "axes[0].legend(title='Final Result')\n",
    "\n",
    "# Success rate by K-Means cluster\n",
    "colors = ['#e74c3c' if r < 50 else '#f39c12' if r < 70 else '#2ecc71' for r in success_rate_km]\n",
    "success_rate_km.plot(kind='bar', ax=axes[1], color=colors, edgecolor='black')\n",
    "axes[1].set_title('Success Rate by K-Means Cluster', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Success Rate (%)')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "axes[1].axhline(df_prep['target'].mean()*100, color='black', linestyle='--', label='Overall')\n",
    "axes[1].legend()\n",
    "\n",
    "for i, v in enumerate(success_rate_km):\n",
    "    axes[1].text(i, v + 1, f'{v:.0f}%', ha='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7ï¸âƒ£ Phase 5: Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"                         EVALUATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"TASK 1: CLASSIFICATION\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Model: Random Forest (Tuned)\")\n",
    "print(f\"Features: {K}\")\n",
    "print(f\"Test AUC-ROC: {roc_auc_score(y_test, y_proba_tuned):.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"CV AUC-ROC: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "\n",
    "print(f\"\\nTop 5 Predictive Features:\")\n",
    "for _, row in importance.head(5).iterrows():\n",
    "    print(f\"  â€¢ {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"TASK 2: CLUSTERING\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nK-Means (k={OPTIMAL_K}, init='k-means++'):\")\n",
    "print(f\"  Silhouette: {kmeans_silhouette:.4f}\")\n",
    "for c, rate in success_rate_km.items():\n",
    "    risk = 'HIGH' if rate < 50 else 'MEDIUM' if rate < 70 else 'LOW'\n",
    "    print(f\"  Cluster {c}: {kmeans_counts[c]:,} students, {rate:.1f}% success â†’ {risk} RISK\")\n",
    "\n",
    "print(f\"\\nDBSCAN (eps={EPS}, min_samples={MIN_SAMPLES}):\")\n",
    "print(f\"  Clusters: {n_clusters_dbscan}, Noise: {n_noise} ({n_noise/len(dbscan_labels)*100:.1f}%)\")\n",
    "if 'dbscan_silhouette' in dir():\n",
    "    print(f\"  Silhouette (excl. noise): {dbscan_silhouette:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"SUCCESS CRITERIA CHECK\")\n",
    "print(\"-\" * 70)\n",
    "auc_val = roc_auc_score(y_test, y_proba_tuned)\n",
    "acc_val = accuracy_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(f\"  {'âœ“' if auc_val > 0.75 else 'âœ—'} AUC-ROC > 0.75: {auc_val:.4f}\")\n",
    "print(f\"  {'âœ“' if acc_val > 0.70 else 'âœ—'} Accuracy > 70%: {acc_val*100:.1f}%\")\n",
    "print(f\"  {'âœ“' if kmeans_silhouette > 0.2 else 'âœ—'} Silhouette > 0.2: {kmeans_silhouette:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8ï¸âƒ£ Phase 6: Deployment Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"                    DEPLOYMENT RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ“‹ EARLY WARNING SYSTEM\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "1. Deploy Random Forest model for at-risk prediction\n",
    "2. Run predictions weekly during first 4 weeks\n",
    "3. Flag students with P(success) < 0.5\n",
    "\n",
    "ðŸ“Š KEY PREDICTIVE INDICATORS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\"\"\")\n",
    "\n",
    "for _, row in importance.head(5).iterrows():\n",
    "    print(f\"  â€¢ {row['Feature']}\")\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ‘¥ CLUSTER-BASED INTERVENTIONS (K-Means)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\"\"\")\n",
    "\n",
    "for c in range(OPTIMAL_K):\n",
    "    rate = success_rate_km[c]\n",
    "    if rate < 50:\n",
    "        print(f\"  Cluster {c} (HIGH RISK - {rate:.0f}%):\")\n",
    "        print(f\"    â†’ Immediate personal tutor contact\")\n",
    "    elif rate < 70:\n",
    "        print(f\"  Cluster {c} (MEDIUM RISK - {rate:.0f}%):\")\n",
    "        print(f\"    â†’ Group study skills workshops\")\n",
    "    else:\n",
    "        print(f\"  Cluster {c} (LOW RISK - {rate:.0f}%):\")\n",
    "        print(f\"    â†’ Light-touch monitoring\")\n",
    "\n",
    "print(\"\"\"\n",
    "âš ï¸ LIMITATIONS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Model based on historical data\n",
    "â€¢ Cannot capture external factors\n",
    "â€¢ Requires retraining each semester\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“ Summary\n",
    "\n",
    "## CRISP-DM Phases Completed\n",
    "\n",
    "| Phase | Status | Key Activities |\n",
    "|-------|--------|----------------|\n",
    "| 1. Business Understanding | âœ“ | Defined objectives, success criteria |\n",
    "| 2. Data Understanding | âœ“ | EDA, outliers, distributions, correlations |\n",
    "| 3. Data Preparation | âœ“ | Missing values, feature engineering, encoding |\n",
    "| 4. Modelling | âœ“ | Classification (3 models), Clustering (K-Means + DBSCAN) |\n",
    "| 5. Evaluation | âœ“ | Metrics, CV, comparison |\n",
    "| 6. Deployment | âœ“ | Recommendations |\n",
    "\n",
    "## Key Techniques Used\n",
    "\n",
    "- **Feature Engineering**: Ratios, binary flags, `pd.cut()` binning, interactions\n",
    "- **Classification**: Logistic Regression, Random Forest, Gradient Boosting\n",
    "- **Clustering**: K-Means (with `k-means++`), DBSCAN\n",
    "- **Visualization**: Yellowbrick `KElbowVisualizer`, Seaborn boxplots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
