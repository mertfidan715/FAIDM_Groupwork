{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "516c2efc",
   "metadata": {},
   "source": [
    "**Building a Temporal Early Warning System for Student Performance**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffabae56",
   "metadata": {},
   "source": [
    "**Problem Description**\n",
    "\n",
    "We have been tasked to develop an early warning system with data provided from the open university\n",
    "\n",
    "This is a temporal prediction problem as at week $t$ we need to make a prediction on the students performance.\n",
    "\n",
    "Key Ideas:\n",
    "\n",
    "- Each student produces **multiple time index snapshots** (week 0, 1, 2, ...)\n",
    "- Each snapshot contains the cumulative features that add up to that week: i.e. a signal that moves up and down some weeks good some bad\n",
    "- We train the model to look at thgis signal of some good weeks some bad.\n",
    "- The model makes a prediction on the historical signals up to that point\n",
    "\n",
    "\n",
    "---\n",
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e780ad6",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcdc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4186b5e",
   "metadata": {},
   "source": [
    "**Data Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743c307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((627031, 80),\n",
       "    student_id code_module code_presentation  week  cum_weekly_clicks_dataplus  \\\n",
       " 0        6516         AAA             2014J    -4                           0   \n",
       " 1        6516         AAA             2014J    -3                           0   \n",
       " 2        6516         AAA             2014J    -2                           0   \n",
       " 3        6516         AAA             2014J    -1                           0   \n",
       " 4        6516         AAA             2014J     0                           0   \n",
       " \n",
       "    cum_weekly_clicks_dualpane  cum_weekly_clicks_externalquiz  \\\n",
       " 0                           0                               0   \n",
       " 1                           0                               0   \n",
       " 2                           0                               0   \n",
       " 3                           0                               0   \n",
       " 4                           0                               0   \n",
       " \n",
       "    cum_weekly_clicks_folder  cum_weekly_clicks_forumng  \\\n",
       " 0                         0                         33   \n",
       " 1                         0                         46   \n",
       " 2                         0                         47   \n",
       " 3                         0                         64   \n",
       " 4                         0                        124   \n",
       " \n",
       "    cum_weekly_clicks_glossary  ...  studied_credits  disability  \\\n",
       " 0                           0  ...               60           N   \n",
       " 1                           0  ...               60           N   \n",
       " 2                           0  ...               60           N   \n",
       " 3                           0  ...               60           N   \n",
       " 4                           0  ...               60           N   \n",
       " \n",
       "    module_presentation_length  date_registration  date_unregistration  \\\n",
       " 0                         269              -52.0                  NaN   \n",
       " 1                         269              -52.0                  NaN   \n",
       " 2                         269              -52.0                  NaN   \n",
       " 3                         269              -52.0                  NaN   \n",
       " 4                         269              -52.0                  NaN   \n",
       " \n",
       "    final_result  target_pass  target_score  target_score_norm  weight_covered  \n",
       " 0          Pass            1          63.5               63.5           100.0  \n",
       " 1          Pass            1          63.5               63.5           100.0  \n",
       " 2          Pass            1          63.5               63.5           100.0  \n",
       " 3          Pass            1          63.5               63.5           100.0  \n",
       " 4          Pass            1          63.5               63.5           100.0  \n",
       " \n",
       " [5 rows x 80 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = Path.cwd().parent  # if notebook is in notebooks/\n",
    "DATA_PATH = ROOT / \"data\" / \"processed\" / \"ews_feature_store.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.shape, df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759dce8e",
   "metadata": {},
   "source": [
    "**Datashape**\n",
    "\n",
    "Each row represents **one student at one week** (a snapshot of that students performance in time)\n",
    "\n",
    "So a single student appears multiple times:\n",
    "\n",
    "- week 0 row: state after week 0 \n",
    "- week 1 row: state after week 1\n",
    "- week 2 row: state after week 2 \n",
    "\n",
    "... and so on\n",
    "\n",
    "These rows contain the **cumulative features** e.g. total clicks so far, total VLE time so far etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c578ed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26074 unique students\n",
      "-4 to 38 weeks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6516</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6516</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6516</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6516</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6516</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6516</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6516</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6516</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id  week\n",
       "0        6516    -4\n",
       "1        6516    -3\n",
       "2        6516    -2\n",
       "3        6516    -1\n",
       "4        6516     0\n",
       "5        6516     1\n",
       "6        6516     2\n",
       "7        6516     3\n",
       "8        6516     4\n",
       "9        6516     5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic checks\n",
    "print(df[\"student_id\"].nunique(), \"unique students\")\n",
    "print(df[\"week\"].min(), \"to\", df[\"week\"].max(), \"weeks\")\n",
    "\n",
    "df[[\"student_id\", \"week\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b820658",
   "metadata": {},
   "source": [
    "**Making predictions**\n",
    "\n",
    "So first we have a prediction week $t$\n",
    "\n",
    "so if $t$ = 3 we are asking \"At week 3, can we predict a final pass/fail?\"\n",
    "\n",
    "we then filter our dataset to include only snapshots/timestamps up to time $t$\n",
    "\n",
    "\n",
    "***(at the moment this is a bit buggy as we need to get rid of data before week 0)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bea6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140376, 80),\n",
       "    week  target_pass\n",
       " 0    -4            1\n",
       " 1    -3            1\n",
       " 2    -2            1\n",
       " 3    -1            1\n",
       " 4     0            1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRED_WEEK = 3\n",
    "\n",
    "df_w = df[df[\"week\"] <= PRED_WEEK].copy()\n",
    "\n",
    "df_w.shape, df_w[[\"week\", \"target_pass\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962a6c7",
   "metadata": {},
   "source": [
    "**Splitting the Groups**\n",
    "\n",
    "Because each student appears multiple times we **must not** split randomly\n",
    "\n",
    "If we split randomly:\n",
    "\n",
    "- The same student could appear in both train and test sets\n",
    "- The model would indirectly \"recognise\" the student\n",
    "- Evaluation would be inflated (leakage)\n",
    "\n",
    "So we split using `student_id` and `GroupShuffleSplit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef81377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: (112726, 79) | Test rows: (27650, 79)\n",
      "Train students: 20553 | Test students: 5139\n"
     ]
    }
   ],
   "source": [
    "# Separate features/target/groups\n",
    "X = df_w.drop(columns=[\"target_pass\"])\n",
    "y = df_w[\"target_pass\"].astype(int)\n",
    "groups = df_w[\"student_id\"]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "print(\"Train rows:\", X_train.shape, \"| Test rows:\", X_test.shape)\n",
    "print(\"Train students:\", X_train[\"student_id\"].nunique(), \"| Test students:\", X_test[\"student_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57d262",
   "metadata": {},
   "source": [
    "With this we then preprocess and fill in some missing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9d71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical/numeric columns\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c3af6",
   "metadata": {},
   "source": [
    "**Then we can Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed65761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.9977970644408174\n",
      "PR-AUC : 0.9985081370324104\n",
      "\n",
      "Confusion matrix (row-level):\n",
      " [[11371   205]\n",
      " [  343 15731]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.982     0.976     11576\n",
      "           1      0.987     0.979     0.983     16074\n",
      "\n",
      "    accuracy                          0.980     27650\n",
      "   macro avg      0.979     0.980     0.980     27650\n",
      "weighted avg      0.980     0.980     0.980     27650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ollie\\Desktop\\WM9QG Group Project\\VLE-analysis\\WM9QG-15_Group_Project\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=10000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "proba = logreg.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, proba))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, proba))\n",
    "print(\"\\nConfusion matrix (row-level):\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"\\nReport:\\n\", classification_report(y_test, pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7275a",
   "metadata": {},
   "source": [
    "**Why is the Confusion Matrix is so large**\n",
    "\n",
    "The confusion Matrix looks inflated as we are evaluating the **rows NOT the students**\n",
    "\n",
    "At `t=3`, each student contributes up to 4 rows\n",
    "\n",
    "- week 0 snapshot \n",
    "- week 1 snapshot \n",
    "- week 2 snap shot\n",
    "- week 3 snapshot\n",
    "\n",
    "So the confusion matrix is counting **student week snapshots**\n",
    "\n",
    "This tells us\n",
    "> \"Across all decision points up to week t, how well does the model classify?\"\n",
    "\n",
    "What we want to know is:\n",
    "> \"At week t, how well does the model flag students?\"\n",
    "\n",
    "***To do this we evaluate the results of the model only at the prediction point (one row per student)!!***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bbd5892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student-level evaluation at week t = 3\n",
      "Test students: 4047\n",
      "ROC-AUC: 0.9829461322990735\n",
      "PR-AUC : 0.9852195697473014\n",
      "\n",
      "Confusion matrix (student-level):\n",
      " [[1606   94]\n",
      " [ 164 2566]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.907     0.945     0.926      1700\n",
      "           1      0.965     0.940     0.952      2730\n",
      "\n",
      "    accuracy                          0.942      4430\n",
      "   macro avg      0.936     0.942     0.939      4430\n",
      "weighted avg      0.943     0.942     0.942      4430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ollie\\Desktop\\WM9QG Group Project\\VLE-analysis\\WM9QG-15_Group_Project\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ONLY at the prediction horizon (one row per student)\n",
    "df_eval = df_w[df_w[\"week\"] == PRED_WEEK].copy()\n",
    "\n",
    "X_eval = df_eval.drop(columns=[\"target_pass\"])\n",
    "y_eval = df_eval[\"target_pass\"].astype(int)\n",
    "groups_eval = df_eval[\"student_id\"]\n",
    "\n",
    "# Group split again at the student level (still important)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X_eval, y_eval, groups=groups_eval))\n",
    "\n",
    "X_train2, X_test2 = X_eval.iloc[train_idx], X_eval.iloc[test_idx]\n",
    "y_train2, y_test2 = y_eval.iloc[train_idx], y_eval.iloc[test_idx]\n",
    "\n",
    "logreg.fit(X_train2, y_train2)\n",
    "\n",
    "proba2 = logreg.predict_proba(X_test2)[:, 1]\n",
    "pred2 = (proba2 >= 0.5).astype(int)\n",
    "\n",
    "print(\"Student-level evaluation at week t =\", PRED_WEEK)\n",
    "print(\"Test students:\", X_test2[\"student_id\"].nunique())\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test2, proba2))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test2, proba2))\n",
    "print(\"\\nConfusion matrix (student-level):\\n\", confusion_matrix(y_test2, pred2))\n",
    "print(\"\\nReport:\\n\", classification_report(y_test2, pred2, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623bade9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- We frame early warning as a **temporal** prediction problem.\n",
    "- We choose a prediction horizon `t` (e.g., week 3).\n",
    "- We train using **snapshots** of student state up to `t`, with cumulative features.\n",
    "- We prevent leakage by splitting using **student_id groups**.\n",
    "- Confusion matrices can be:\n",
    "  - **Row-level** (student-week snapshots): larger sample size\n",
    "  - **Student-level** (fixed horizon `week == t`): one prediction per student, matches real-world EWS decisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43b01c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
